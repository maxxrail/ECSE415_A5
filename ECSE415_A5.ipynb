{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a341e8cf",
   "metadata": {},
   "source": [
    "## Imports and Setup \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9176dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 0. Imports & Global Settings\n",
    "# ============================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# YOLOv8\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# DeepSORT\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Plotting / debug (optional)\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c092360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 0.1 Paths & Constants\n",
    "# ============================================\n",
    "BASE_DIR = Path(\"Object_Tracking\")\n",
    "\n",
    "TASK1_IMAGES_DIR = BASE_DIR / \"Task1\" / \"images\"\n",
    "TASK1_GT_PATH    = BASE_DIR / \"Task1\" / \"gt\" / \"gt.txt\"\n",
    "\n",
    "TASK2_IMAGES_DIR = BASE_DIR / \"Task2\" / \"images\"\n",
    "\n",
    "# Output paths\n",
    "TASK1_INPUT_VIDEO  = Path(\"task1_input.mp4\")\n",
    "TASK1_OUTPUT_VIDEO = Path(\"task1.mp4\")\n",
    "TASK2_OUTPUT_VIDEO = Path(\"task2.mp4\")\n",
    "TASK2_COUNTS_CSV   = Path(\"task2_count.csv\")\n",
    "\n",
    "FPS_TASK1 = 14\n",
    "FPS_TASK2 = 14\n",
    "\n",
    "# YOLO weights\n",
    "YOLO_WEIGHTS = \"yolov8s.pt\"  # or 'yolov8m.pt' if you want a heavier model\n",
    "YOLO_IMGSZ = 1920       # you’re using full-res\n",
    "YOLO_CONF = 0.2          # confidence threshold\n",
    "# Pick CUDA if available, otherwise CPU\n",
    "DEVICE = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb55f22a",
   "metadata": {},
   "source": [
    "## 1. Data Preparation (Task 1 – images → video @ 14 FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da513638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: task1_input.mp4 (429 frames at 14 FPS)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1. Convert Task1 images to video (task1_input.mp4)\n",
    "# ============================================\n",
    "def images_to_video(image_dir: Path, output_path: Path, fps: int = 14):\n",
    "    \"\"\"\n",
    "    Convert all images in image_dir to a video at the given fps.\n",
    "    Assumes images are named so that lexicographic sort is correct frame order\n",
    "    (e.g., 000001.jpg, 000002.jpg, ...).\n",
    "    \"\"\"\n",
    "    image_files = sorted(\n",
    "        [p for p in image_dir.iterdir() if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]]\n",
    "    )\n",
    "    assert len(image_files) > 0, f\"No images found in {image_dir}\"\n",
    "\n",
    "    # Read first image to get frame size\n",
    "    first_frame = cv2.imread(str(image_files[0]))\n",
    "    assert first_frame is not None, f\"Could not read first image {image_files[0]}\"\n",
    "\n",
    "    height, width = first_frame.shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "\n",
    "    for img_path in image_files:\n",
    "        frame = cv2.imread(str(img_path))\n",
    "        if frame is None:\n",
    "            print(f\"Warning: could not read {img_path}, skipping.\")\n",
    "            continue\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Saved video: {output_path} ({len(image_files)} frames at {fps} FPS)\")\n",
    "\n",
    "# Run for Task1\n",
    "images_to_video(TASK1_IMAGES_DIR, TASK1_INPUT_VIDEO, fps=FPS_TASK1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522e94d",
   "metadata": {},
   "source": [
    "## 2. YOLOv8 + DeepSORT Tracking (Task 2 – Task1 video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1387df",
   "metadata": {},
   "source": [
    "### 2.1 Initialize YOLO and DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "811a8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2.1 Initialize YOLOv8 and DeepSORT\n",
    "# ============================================\n",
    "def init_yolo(weights_path: str = YOLO_WEIGHTS, device: str = DEVICE):\n",
    "    \"\"\"\n",
    "    Initialize YOLOv8 model on CPU or CUDA if available.\n",
    "    \"\"\"\n",
    "    model = YOLO(weights_path)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def init_deepsort():\n",
    "    \"\"\"\n",
    "    Initialize DeepSort tracker from deep_sort_realtime.\n",
    "    \"\"\"\n",
    "    tracker = DeepSort(\n",
    "        max_age=30,\n",
    "        n_init=3,\n",
    "        nn_budget=100,\n",
    "        max_iou_distance=0.7,\n",
    "    )\n",
    "    return tracker\n",
    "\n",
    "\n",
    "yolo_model = init_yolo()\n",
    "deepsort_tracker = init_deepsort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6a58de",
   "metadata": {},
   "source": [
    "### 2.2 Helper: Run tracker on a video & save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d7ecc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking done. Saved video to task1.mp4\n",
      "Tracking results saved to task1_tracks.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 2.2 Run YOLOv8 + DeepSORT on a video (Task1)\n",
    "# ============================================\n",
    "def run_tracking(\n",
    "    input_video_path: Path,\n",
    "    output_video_path: Path,\n",
    "    tracker_txt_out: Path,\n",
    "    yolo_model,\n",
    "    deepsort_tracker,\n",
    "    fps: int,\n",
    "    conf: float = YOLO_CONF\n",
    "):\n",
    "    \"\"\"\n",
    "    Run YOLOv8 + DeepSORT tracking on a video.\n",
    "\n",
    "    Outputs:\n",
    "      - Annotated video with tracking boxes & IDs\n",
    "      - Text file with tracking results:\n",
    "        <frame>, <id>, <bb_left>, <bb_top>, <bb_width>, <bb_height>\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(str(input_video_path))\n",
    "    assert cap.isOpened(), f\"Cannot open {input_video_path}\"\n",
    "\n",
    "    # Get frame size from first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    assert ret, \"Could not read first frame\"\n",
    "    height, width = first_frame.shape[:2]\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # reset to start\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(str(output_video_path), fourcc, fps, (width, height))\n",
    "\n",
    "    all_tracks = []  # (frame_idx, track_id, bb_left, bb_top, bb_width, bb_height)\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_idx += 1\n",
    "\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # YOLO inference (more generous settings)\n",
    "        results = yolo_model(frame, imgsz=YOLO_IMGSZ, conf=conf, verbose=False)[0]\n",
    "        boxes = results.boxes\n",
    "\n",
    "        detections = []\n",
    "        if boxes is not None and len(boxes) > 0:\n",
    "            xyxy = boxes.xyxy.cpu().numpy()\n",
    "            confs = boxes.conf.cpu().numpy()\n",
    "            clss = boxes.cls.cpu().numpy()\n",
    "\n",
    "            for bbox, score, cls in zip(xyxy, confs, clss):\n",
    "                # COCO class 0 = 'person'\n",
    "                if int(cls) != 0:\n",
    "                    continue\n",
    "                x1, y1, x2, y2 = bbox\n",
    "\n",
    "                # DeepSORT expects [x, y, w, h] (top-left + width/height)\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                detections.append(([x1, y1, w, h], float(score), \"person\"))\n",
    "\n",
    "        tracks = deepsort_tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 0:\n",
    "                continue\n",
    "\n",
    "            track_id = track.track_id\n",
    "\n",
    "            # Use original detection box for better IoU with GT\n",
    "            l, t, r, b = track.to_ltrb(orig=True)\n",
    "\n",
    "            # Clamp to image\n",
    "            l = max(0, min(int(l), width - 1))\n",
    "            r = max(0, min(int(r), width - 1))\n",
    "            t = max(0, min(int(t), height - 1))\n",
    "            b = max(0, min(int(b), height - 1))\n",
    "\n",
    "            bb_left = float(l)\n",
    "            bb_top = float(t)\n",
    "            bb_width = float(r - l)\n",
    "            bb_height = float(b - t)\n",
    "\n",
    "            all_tracks.append(\n",
    "                (frame_idx, int(track_id), bb_left, bb_top, bb_width, bb_height)\n",
    "            )\n",
    "\n",
    "            # Draw\n",
    "            cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"ID {track_id}\",\n",
    "                (l, t - 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Save tracking results to txt\n",
    "    tracker_txt_out = Path(tracker_txt_out)\n",
    "    with tracker_txt_out.open(\"w\") as f:\n",
    "        for (frame_idx, track_id, bb_left, bb_top, bb_width, bb_height) in all_tracks:\n",
    "            f.write(\n",
    "                f\"{frame_idx},{track_id},{bb_left:.2f},{bb_top:.2f},{bb_width:.2f},{bb_height:.2f}\\n\"\n",
    "            )\n",
    "\n",
    "    print(f\"Tracking done. Saved video to {output_video_path}\")\n",
    "    print(f\"Tracking results saved to {tracker_txt_out}\")\n",
    "\n",
    "\n",
    "# Run tracking for Task1\n",
    "TASK1_TRACKS_TXT = Path(\"task1_tracks.txt\")\n",
    "run_tracking(\n",
    "    TASK1_INPUT_VIDEO,\n",
    "    TASK1_OUTPUT_VIDEO,\n",
    "    TASK1_TRACKS_TXT,\n",
    "    yolo_model,\n",
    "    deepsort_tracker,\n",
    "    fps=FPS_TASK1,\n",
    "    conf=YOLO_CONF\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46ace0",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation: MOTA (Task 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be77b2",
   "metadata": {},
   "source": [
    "### 3.1 Load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ae07cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GT frames: 429\n",
      "Total GT boxes: 19870\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3.1 Load ground truth annotations (Task1/gt/gt.txt)\n",
    "# Using only the first 6 columns:\n",
    "# <frame>, <id>, <bb_left>, <bb_top>, <bb_width>, <bb_height>, ...\n",
    "# ============================================\n",
    "def load_gt(gt_path: Path):\n",
    "    \"\"\"\n",
    "    Load ground truth from MOT-style gt.txt.\n",
    "\n",
    "    Assumes columns:\n",
    "      1: frame\n",
    "      2: id\n",
    "      3: bb_left\n",
    "      4: bb_top\n",
    "      5: bb_width\n",
    "      6: bb_height\n",
    "      [7: conf (optional)]\n",
    "      [8: class (optional, 1 = pedestrian)]\n",
    "      [9+: other fields, ignored]\n",
    "\n",
    "    We:\n",
    "      - skip lines with conf <= 0 (unlabeled / ignored)\n",
    "      - if class column exists, keep only class == 1 (pedestrians)\n",
    "    \"\"\"\n",
    "    gt_by_frame = defaultdict(list)\n",
    "\n",
    "    with open(gt_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            cols = line.split(\",\")\n",
    "            if len(cols) < 6:\n",
    "                continue\n",
    "\n",
    "            frame = int(cols[0])\n",
    "            obj_id = int(cols[1])\n",
    "            bb_left   = float(cols[2])\n",
    "            bb_top    = float(cols[3])\n",
    "            bb_width  = float(cols[4])\n",
    "            bb_height = float(cols[5])\n",
    "\n",
    "            # Optional 7th column: conf\n",
    "            if len(cols) >= 7:\n",
    "                conf = float(cols[6])\n",
    "                # MOT convention: conf <= 0 => ignore\n",
    "                if conf <= 0:\n",
    "                    continue\n",
    "\n",
    "            # Optional 8th column: class (1 = pedestrian)\n",
    "            if len(cols) >= 8:\n",
    "                cls = int(cols[7])\n",
    "                if cls != 1:\n",
    "                    # keep only pedestrians\n",
    "                    continue\n",
    "\n",
    "            gt_by_frame[frame].append(\n",
    "                {\n",
    "                    \"id\": obj_id,\n",
    "                    \"bbox\": [bb_left, bb_top, bb_width, bb_height],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return gt_by_frame\n",
    "\n",
    "gt_by_frame = load_gt(TASK1_GT_PATH)\n",
    "print(\"Loaded GT frames:\", len(gt_by_frame))\n",
    "print(\"Total GT boxes:\", sum(len(v) for v in gt_by_frame.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5095a93",
   "metadata": {},
   "source": [
    "### 3.2 Load predictions (tracker output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f878415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded predictions for 427 frames\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3.2 Load tracking results from our tracker output txt\n",
    "# Format: <frame>, <id>, <bb_left>, <bb_top>, <bb_width>, <bb_height>\n",
    "# ============================================\n",
    "def load_predictions(pred_path: Path):\n",
    "    pred_by_frame = defaultdict(list)\n",
    "    with pred_path.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            parts = line.strip().split(\",\")\n",
    "            frame = int(parts[0])\n",
    "            track_id = int(parts[1])\n",
    "            x = float(parts[2])\n",
    "            y = float(parts[3])\n",
    "            w = float(parts[4])\n",
    "            h = float(parts[5])\n",
    "\n",
    "            pred_by_frame[frame].append(\n",
    "                {\n",
    "                    \"id\": track_id,\n",
    "                    \"bbox\": np.array([x, y, w, h], dtype=float),\n",
    "                }\n",
    "            )\n",
    "    return pred_by_frame\n",
    "\n",
    "pred_by_frame = load_predictions(TASK1_TRACKS_TXT)\n",
    "print(f\"Loaded predictions for {len(pred_by_frame)} frames\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44efd6ff",
   "metadata": {},
   "source": [
    "### 3.3 IoU, Hungarian matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db6fd9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3.3 IoU & matching utilities\n",
    "# ============================================\n",
    "def xywh_to_xyxy(box_xywh):\n",
    "    \"\"\"Convert [x, y, w, h] -> [x1, y1, x2, y2].\"\"\"\n",
    "    x, y, w, h = box_xywh\n",
    "    return np.array([x, y, x + w, y + h], dtype=float)\n",
    "\n",
    "\n",
    "def compute_iou_matrix(gt_boxes_xywh, pred_boxes_xywh):\n",
    "    \"\"\"\n",
    "    Compute IoU matrix between:\n",
    "      - gt_boxes_xywh: list of [x, y, w, h]\n",
    "      - pred_boxes_xywh: list of [x, y, w, h]\n",
    "    Returns: (N_gt, N_pred) IoU matrix.\n",
    "    \"\"\"\n",
    "    N = len(gt_boxes_xywh)\n",
    "    M = len(pred_boxes_xywh)\n",
    "\n",
    "    if N == 0 or M == 0:\n",
    "        return np.zeros((N, M), dtype=float)\n",
    "\n",
    "    gt = np.array([xywh_to_xyxy(b) for b in gt_boxes_xywh], dtype=float)  # (N,4)\n",
    "    pr = np.array([xywh_to_xyxy(b) for b in pred_boxes_xywh], dtype=float)  # (M,4)\n",
    "\n",
    "    gt_x1 = gt[:, 0][:, None]\n",
    "    gt_y1 = gt[:, 1][:, None]\n",
    "    gt_x2 = gt[:, 2][:, None]\n",
    "    gt_y2 = gt[:, 3][:, None]\n",
    "\n",
    "    pr_x1 = pr[:, 0][None, :]\n",
    "    pr_y1 = pr[:, 1][None, :]\n",
    "    pr_x2 = pr[:, 2][None, :]\n",
    "    pr_y2 = pr[:, 3][None, :]\n",
    "\n",
    "    inter_x1 = np.maximum(gt_x1, pr_x1)\n",
    "    inter_y1 = np.maximum(gt_y1, pr_y1)\n",
    "    inter_x2 = np.minimum(gt_x2, pr_x2)\n",
    "    inter_y2 = np.minimum(gt_y2, pr_y2)\n",
    "\n",
    "    inter_w = np.clip(inter_x2 - inter_x1, a_min=0, a_max=None)\n",
    "    inter_h = np.clip(inter_y2 - inter_y1, a_min=0, a_max=None)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    gt_area = (gt_x2 - gt_x1) * (gt_y2 - gt_y1)   # (N,1)\n",
    "    pr_area = (pr_x2 - pr_x1) * (pr_y2 - pr_y1)   # (1,M)\n",
    "    union_area = gt_area + pr_area - inter_area\n",
    "\n",
    "    iou = np.zeros_like(inter_area)\n",
    "    mask = union_area > 0\n",
    "    iou[mask] = inter_area[mask] / union_area[mask]\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecceae6",
   "metadata": {},
   "source": [
    "### 3.4 Compute MOTA, FP, FN, IDSW, GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63f4ecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOTA: 0.4161\n",
      "Total GT:   19870\n",
      "Total FP:   3189\n",
      "Total FN:   7877\n",
      "Total IDSW: 536\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3.4 Compute MOTA, FP, FN, IDSW, GT\n",
    "# ============================================\n",
    "def compute_mota(gt_by_frame, pred_by_frame, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compute MOTA, and totals of FP, FN, IDSW, and GT.\n",
    "    Following the definition given in the assignment.\n",
    "    \"\"\"\n",
    "    frames = sorted(gt_by_frame.keys())       # frames with GT\n",
    "    all_frames = frames                       # just use GT frames\n",
    "\n",
    "\n",
    "    total_FP = 0\n",
    "    total_FN = 0\n",
    "    total_IDSW = 0\n",
    "    total_GT = 0\n",
    "\n",
    "    # For ID switch tracking: gt_id -> last matched pred_id\n",
    "    prev_match_for_gt = {}\n",
    "\n",
    "    for t in all_frames:\n",
    "        gt_objs = gt_by_frame.get(t, [])\n",
    "        pr_objs = pred_by_frame.get(t, [])\n",
    "\n",
    "        gt_boxes = [g[\"bbox\"] for g in gt_objs]\n",
    "        gt_ids = [g[\"id\"] for g in gt_objs]\n",
    "\n",
    "        pr_boxes = [p[\"bbox\"] for p in pr_objs]\n",
    "        pr_ids = [p[\"id\"] for p in pr_objs]\n",
    "\n",
    "        N = len(gt_boxes)\n",
    "        M = len(pr_boxes)\n",
    "\n",
    "        total_GT += N\n",
    "\n",
    "        if N == 0 and M == 0:\n",
    "            # nothing here\n",
    "            continue\n",
    "\n",
    "        # IoU matrix\n",
    "        iou_mat = compute_iou_matrix(gt_boxes, pr_boxes)\n",
    "\n",
    "        if N > 0 and M > 0:\n",
    "            # Cost matrix for Hungarian: we want to maximize IoU,\n",
    "            # so we minimize (1 - IoU). Set cost very high if IoU < threshold.\n",
    "            cost = 1.0 - iou_mat\n",
    "            cost[iou_mat < iou_threshold] = 1e6\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_gt_idx = set()\n",
    "            matched_pr_idx = set()\n",
    "\n",
    "            # Evaluate matches above threshold\n",
    "            for r, c in zip(row_ind, col_ind):\n",
    "                if iou_mat[r, c] >= iou_threshold:\n",
    "                    matched_gt_idx.add(r)\n",
    "                    matched_pr_idx.add(c)\n",
    "\n",
    "                    gt_id = gt_ids[r]\n",
    "                    pr_id = pr_ids[c]\n",
    "\n",
    "                    # Identity switch?\n",
    "                    if gt_id in prev_match_for_gt:\n",
    "                        if prev_match_for_gt[gt_id] != pr_id:\n",
    "                            total_IDSW += 1\n",
    "                    prev_match_for_gt[gt_id] = pr_id\n",
    "\n",
    "            # FN: GT with no match\n",
    "            FN_t = N - len(matched_gt_idx)\n",
    "\n",
    "            # FP: predictions with no match\n",
    "            FP_t = M - len(matched_pr_idx)\n",
    "\n",
    "        elif N == 0 and M > 0:\n",
    "            # All predictions are FP\n",
    "            FP_t = M\n",
    "            FN_t = 0\n",
    "\n",
    "        elif N > 0 and M == 0:\n",
    "            # All GT are FN\n",
    "            FN_t = N\n",
    "            FP_t = 0\n",
    "\n",
    "        total_FN += FN_t\n",
    "        total_FP += FP_t\n",
    "\n",
    "    if total_GT == 0:\n",
    "        mota = 0.0\n",
    "    else:\n",
    "        mota = 1.0 - (total_FN + total_FP + total_IDSW) / total_GT\n",
    "\n",
    "    return mota, total_FP, total_FN, total_IDSW, total_GT\n",
    "\n",
    "\n",
    "mota, total_FP, total_FN, total_IDSW, total_GT = compute_mota(\n",
    "    gt_by_frame, pred_by_frame, iou_threshold=0.5\n",
    ")\n",
    "\n",
    "print(f\"MOTA: {mota:.4f}\")\n",
    "print(f\"Total GT:   {total_GT}\")\n",
    "print(f\"Total FP:   {total_FP}\")\n",
    "print(f\"Total FN:   {total_FN}\")\n",
    "print(f\"Total IDSW: {total_IDSW}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c84cb4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames with GT: 429\n",
      "Total GT boxes: 19870 -> avg per frame: 46.31701631701632\n",
      "Total pred boxes on those frames: 15182 -> avg per frame: 35.38927738927739\n"
     ]
    }
   ],
   "source": [
    "# Quick debug: how many GT vs predictions per frame?\n",
    "all_gt_frames = sorted(gt_by_frame.keys())\n",
    "all_pred_frames = sorted(pred_by_frame.keys())\n",
    "\n",
    "total_GT = sum(len(gt_by_frame[f]) for f in all_gt_frames)\n",
    "total_pred = sum(len(pred_by_frame.get(f, [])) for f in all_gt_frames)\n",
    "\n",
    "print(\"Frames with GT:\", len(all_gt_frames))\n",
    "print(\"Total GT boxes:\", total_GT, \"-> avg per frame:\", total_GT / len(all_gt_frames))\n",
    "print(\"Total pred boxes on those frames:\", total_pred, \"-> avg per frame:\", total_pred / len(all_gt_frames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01be02",
   "metadata": {},
   "source": [
    "## 4. Prediction & Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62542e3",
   "metadata": {},
   "source": [
    "### 4.1 Convert Task2 images to a video and track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca5c1afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame    1: 46 people, 46 detections, 46 tracks\n",
      "Frame    2: 45 people, 45 detections, 45 tracks\n",
      "Frame    3: 46 people, 46 detections, 46 tracks\n",
      "Frame    4: 48 people, 48 detections, 48 tracks\n",
      "Frame    5: 45 people, 45 detections, 45 tracks\n",
      "Frame    6: 46 people, 46 detections, 48 tracks\n",
      "Frame    7: 43 people, 43 detections, 46 tracks\n",
      "Frame    8: 41 people, 41 detections, 45 tracks\n",
      "Frame    9: 46 people, 46 detections, 47 tracks\n",
      "Frame   10: 42 people, 42 detections, 45 tracks\n",
      "Frame   11: 42 people, 42 detections, 45 tracks\n",
      "Frame   12: 41 people, 41 detections, 46 tracks\n",
      "Frame   13: 42 people, 42 detections, 46 tracks\n",
      "Frame   14: 41 people, 41 detections, 46 tracks\n",
      "Frame   15: 40 people, 40 detections, 46 tracks\n",
      "Frame   16: 41 people, 41 detections, 46 tracks\n",
      "Frame   17: 39 people, 39 detections, 46 tracks\n",
      "Frame   18: 39 people, 39 detections, 46 tracks\n",
      "Frame   19: 41 people, 41 detections, 47 tracks\n",
      "Frame   20: 39 people, 39 detections, 46 tracks\n",
      "Frame   21: 41 people, 41 detections, 49 tracks\n",
      "Frame   22: 37 people, 37 detections, 47 tracks\n",
      "Frame   23: 37 people, 37 detections, 46 tracks\n",
      "Frame   24: 38 people, 38 detections, 47 tracks\n",
      "Frame   25: 38 people, 38 detections, 47 tracks\n",
      "Frame   26: 39 people, 39 detections, 47 tracks\n",
      "Frame   27: 40 people, 40 detections, 48 tracks\n",
      "Frame   28: 37 people, 37 detections, 47 tracks\n",
      "Frame   29: 37 people, 37 detections, 47 tracks\n",
      "Frame   30: 38 people, 38 detections, 48 tracks\n",
      "Frame   31: 38 people, 38 detections, 48 tracks\n",
      "Frame   32: 37 people, 37 detections, 48 tracks\n",
      "Frame   33: 39 people, 39 detections, 49 tracks\n",
      "Frame   34: 41 people, 41 detections, 50 tracks\n",
      "Frame   35: 38 people, 38 detections, 49 tracks\n",
      "Frame   36: 37 people, 37 detections, 49 tracks\n",
      "Frame   37: 37 people, 37 detections, 50 tracks\n",
      "Frame   38: 36 people, 36 detections, 48 tracks\n",
      "Frame   39: 37 people, 37 detections, 49 tracks\n",
      "Frame   40: 37 people, 37 detections, 48 tracks\n",
      "Frame   41: 37 people, 37 detections, 48 tracks\n",
      "Frame   42: 37 people, 37 detections, 49 tracks\n",
      "Frame   43: 41 people, 41 detections, 51 tracks\n",
      "Frame   44: 38 people, 38 detections, 50 tracks\n",
      "Frame   45: 39 people, 39 detections, 49 tracks\n",
      "Frame   46: 37 people, 37 detections, 48 tracks\n",
      "Frame   47: 35 people, 35 detections, 48 tracks\n",
      "Frame   48: 38 people, 38 detections, 50 tracks\n",
      "Frame   49: 38 people, 38 detections, 50 tracks\n",
      "Frame   50: 37 people, 37 detections, 50 tracks\n",
      "Frame   51: 38 people, 38 detections, 49 tracks\n",
      "Frame   52: 40 people, 40 detections, 49 tracks\n",
      "Frame   53: 39 people, 39 detections, 48 tracks\n",
      "Frame   54: 41 people, 41 detections, 49 tracks\n",
      "Frame   55: 39 people, 39 detections, 48 tracks\n",
      "Frame   56: 38 people, 38 detections, 47 tracks\n",
      "Frame   57: 36 people, 36 detections, 47 tracks\n",
      "Frame   58: 36 people, 36 detections, 47 tracks\n",
      "Frame   59: 38 people, 38 detections, 47 tracks\n",
      "Frame   60: 37 people, 37 detections, 47 tracks\n",
      "Frame   61: 37 people, 37 detections, 48 tracks\n",
      "Frame   62: 36 people, 36 detections, 46 tracks\n",
      "Frame   63: 37 people, 37 detections, 46 tracks\n",
      "Frame   64: 39 people, 39 detections, 48 tracks\n",
      "Frame   65: 40 people, 40 detections, 49 tracks\n",
      "Frame   66: 37 people, 37 detections, 46 tracks\n",
      "Frame   67: 37 people, 37 detections, 46 tracks\n",
      "Frame   68: 39 people, 39 detections, 47 tracks\n",
      "Frame   69: 37 people, 37 detections, 46 tracks\n",
      "Frame   70: 38 people, 38 detections, 46 tracks\n",
      "Frame   71: 37 people, 37 detections, 47 tracks\n",
      "Frame   72: 37 people, 37 detections, 46 tracks\n",
      "Frame   73: 39 people, 39 detections, 47 tracks\n",
      "Frame   74: 38 people, 38 detections, 47 tracks\n",
      "Frame   75: 38 people, 38 detections, 47 tracks\n",
      "Frame   76: 40 people, 40 detections, 47 tracks\n",
      "Frame   77: 39 people, 39 detections, 48 tracks\n",
      "Frame   78: 38 people, 38 detections, 48 tracks\n",
      "Frame   79: 39 people, 39 detections, 47 tracks\n",
      "Frame   80: 39 people, 39 detections, 45 tracks\n",
      "Frame   81: 38 people, 38 detections, 46 tracks\n",
      "Frame   82: 38 people, 38 detections, 47 tracks\n",
      "Frame   83: 38 people, 38 detections, 48 tracks\n",
      "Frame   84: 38 people, 38 detections, 47 tracks\n",
      "Frame   85: 40 people, 40 detections, 48 tracks\n",
      "Frame   86: 38 people, 38 detections, 44 tracks\n",
      "Frame   87: 40 people, 40 detections, 45 tracks\n",
      "Frame   88: 38 people, 38 detections, 43 tracks\n",
      "Frame   89: 39 people, 39 detections, 44 tracks\n",
      "Frame   90: 39 people, 39 detections, 44 tracks\n",
      "Frame   91: 38 people, 38 detections, 43 tracks\n",
      "Frame   92: 38 people, 38 detections, 43 tracks\n",
      "Frame   93: 38 people, 38 detections, 43 tracks\n",
      "Frame   94: 37 people, 37 detections, 43 tracks\n",
      "Frame   95: 38 people, 38 detections, 44 tracks\n",
      "Frame   96: 40 people, 40 detections, 45 tracks\n",
      "Frame   97: 38 people, 38 detections, 44 tracks\n",
      "Frame   98: 39 people, 39 detections, 45 tracks\n",
      "Frame   99: 38 people, 38 detections, 44 tracks\n",
      "Frame  100: 37 people, 37 detections, 44 tracks\n",
      "Frame  101: 37 people, 37 detections, 44 tracks\n",
      "Frame  102: 37 people, 37 detections, 45 tracks\n",
      "Frame  103: 37 people, 37 detections, 44 tracks\n",
      "Frame  104: 38 people, 38 detections, 45 tracks\n",
      "Frame  105: 38 people, 38 detections, 45 tracks\n",
      "Frame  106: 36 people, 36 detections, 45 tracks\n",
      "Frame  107: 38 people, 38 detections, 46 tracks\n",
      "Frame  108: 36 people, 36 detections, 44 tracks\n",
      "Frame  109: 37 people, 37 detections, 44 tracks\n",
      "Frame  110: 37 people, 37 detections, 44 tracks\n",
      "Frame  111: 39 people, 39 detections, 44 tracks\n",
      "Frame  112: 37 people, 37 detections, 43 tracks\n",
      "Frame  113: 36 people, 36 detections, 43 tracks\n",
      "Frame  114: 37 people, 37 detections, 43 tracks\n",
      "Frame  115: 38 people, 38 detections, 43 tracks\n",
      "Frame  116: 40 people, 40 detections, 45 tracks\n",
      "Frame  117: 38 people, 38 detections, 43 tracks\n",
      "Frame  118: 38 people, 38 detections, 43 tracks\n",
      "Frame  119: 38 people, 38 detections, 42 tracks\n",
      "Frame  120: 36 people, 36 detections, 42 tracks\n",
      "Frame  121: 39 people, 39 detections, 42 tracks\n",
      "Frame  122: 37 people, 37 detections, 42 tracks\n",
      "Frame  123: 38 people, 38 detections, 44 tracks\n",
      "Frame  124: 36 people, 36 detections, 43 tracks\n",
      "Frame  125: 36 people, 36 detections, 42 tracks\n",
      "Frame  126: 37 people, 37 detections, 43 tracks\n",
      "Frame  127: 37 people, 37 detections, 44 tracks\n",
      "Frame  128: 41 people, 41 detections, 46 tracks\n",
      "Frame  129: 40 people, 40 detections, 46 tracks\n",
      "Frame  130: 37 people, 37 detections, 45 tracks\n",
      "Frame  131: 39 people, 39 detections, 46 tracks\n",
      "Frame  132: 39 people, 39 detections, 47 tracks\n",
      "Frame  133: 40 people, 40 detections, 46 tracks\n",
      "Frame  134: 37 people, 37 detections, 45 tracks\n",
      "Frame  135: 38 people, 38 detections, 45 tracks\n",
      "Frame  136: 38 people, 38 detections, 45 tracks\n",
      "Frame  137: 36 people, 36 detections, 45 tracks\n",
      "Frame  138: 38 people, 38 detections, 46 tracks\n",
      "Frame  139: 36 people, 36 detections, 45 tracks\n",
      "Frame  140: 37 people, 37 detections, 46 tracks\n",
      "Frame  141: 38 people, 38 detections, 46 tracks\n",
      "Frame  142: 36 people, 36 detections, 45 tracks\n",
      "Frame  143: 36 people, 36 detections, 45 tracks\n",
      "Frame  144: 37 people, 37 detections, 45 tracks\n",
      "Frame  145: 37 people, 37 detections, 45 tracks\n",
      "Frame  146: 35 people, 35 detections, 46 tracks\n",
      "Frame  147: 36 people, 36 detections, 46 tracks\n",
      "Frame  148: 36 people, 36 detections, 45 tracks\n",
      "Frame  149: 36 people, 36 detections, 45 tracks\n",
      "Frame  150: 37 people, 37 detections, 46 tracks\n",
      "Frame  151: 41 people, 41 detections, 48 tracks\n",
      "Frame  152: 38 people, 38 detections, 44 tracks\n",
      "Frame  153: 39 people, 39 detections, 45 tracks\n",
      "Frame  154: 40 people, 40 detections, 46 tracks\n",
      "Frame  155: 39 people, 39 detections, 45 tracks\n",
      "Frame  156: 40 people, 40 detections, 45 tracks\n",
      "Frame  157: 38 people, 38 detections, 44 tracks\n",
      "Frame  158: 40 people, 40 detections, 45 tracks\n",
      "Frame  159: 41 people, 41 detections, 44 tracks\n",
      "Frame  160: 41 people, 41 detections, 45 tracks\n",
      "Frame  161: 41 people, 41 detections, 46 tracks\n",
      "Frame  162: 40 people, 40 detections, 44 tracks\n",
      "Frame  163: 40 people, 40 detections, 43 tracks\n",
      "Frame  164: 38 people, 38 detections, 43 tracks\n",
      "Frame  165: 42 people, 42 detections, 43 tracks\n",
      "Frame  166: 39 people, 39 detections, 43 tracks\n",
      "Frame  167: 40 people, 40 detections, 43 tracks\n",
      "Frame  168: 38 people, 38 detections, 43 tracks\n",
      "Frame  169: 40 people, 40 detections, 44 tracks\n",
      "Frame  170: 39 people, 39 detections, 44 tracks\n",
      "Frame  171: 42 people, 42 detections, 44 tracks\n",
      "Frame  172: 42 people, 42 detections, 44 tracks\n",
      "Frame  173: 41 people, 41 detections, 44 tracks\n",
      "Frame  174: 43 people, 43 detections, 45 tracks\n",
      "Frame  175: 41 people, 41 detections, 44 tracks\n",
      "Frame  176: 42 people, 42 detections, 45 tracks\n",
      "Frame  177: 39 people, 39 detections, 44 tracks\n",
      "Frame  178: 41 people, 41 detections, 44 tracks\n",
      "Frame  179: 41 people, 41 detections, 44 tracks\n",
      "Frame  180: 42 people, 42 detections, 44 tracks\n",
      "Frame  181: 42 people, 42 detections, 44 tracks\n",
      "Frame  182: 42 people, 42 detections, 44 tracks\n",
      "Frame  183: 42 people, 42 detections, 44 tracks\n",
      "Frame  184: 41 people, 41 detections, 44 tracks\n",
      "Frame  185: 41 people, 41 detections, 43 tracks\n",
      "Frame  186: 41 people, 41 detections, 43 tracks\n",
      "Frame  187: 42 people, 42 detections, 43 tracks\n",
      "Frame  188: 42 people, 42 detections, 43 tracks\n",
      "Frame  189: 41 people, 41 detections, 43 tracks\n",
      "Frame  190: 42 people, 42 detections, 43 tracks\n",
      "Frame  191: 43 people, 43 detections, 44 tracks\n",
      "Frame  192: 40 people, 40 detections, 43 tracks\n",
      "Frame  193: 42 people, 42 detections, 43 tracks\n",
      "Frame  194: 40 people, 40 detections, 43 tracks\n",
      "Frame  195: 42 people, 42 detections, 44 tracks\n",
      "Frame  196: 40 people, 40 detections, 44 tracks\n",
      "Frame  197: 39 people, 39 detections, 43 tracks\n",
      "Frame  198: 41 people, 41 detections, 44 tracks\n",
      "Frame  199: 42 people, 42 detections, 43 tracks\n",
      "Frame  200: 40 people, 40 detections, 44 tracks\n",
      "Frame  201: 42 people, 42 detections, 45 tracks\n",
      "Frame  202: 46 people, 46 detections, 47 tracks\n",
      "Frame  203: 44 people, 44 detections, 46 tracks\n",
      "Frame  204: 43 people, 43 detections, 48 tracks\n",
      "Frame  205: 42 people, 42 detections, 47 tracks\n",
      "Frame  206: 42 people, 42 detections, 46 tracks\n",
      "Frame  207: 41 people, 41 detections, 46 tracks\n",
      "Frame  208: 41 people, 41 detections, 46 tracks\n",
      "Frame  209: 41 people, 41 detections, 46 tracks\n",
      "Frame  210: 40 people, 40 detections, 46 tracks\n",
      "Frame  211: 41 people, 41 detections, 46 tracks\n",
      "Frame  212: 42 people, 42 detections, 46 tracks\n",
      "Frame  213: 42 people, 42 detections, 46 tracks\n",
      "Frame  214: 43 people, 43 detections, 46 tracks\n",
      "Frame  215: 42 people, 42 detections, 47 tracks\n",
      "Frame  216: 42 people, 42 detections, 46 tracks\n",
      "Frame  217: 42 people, 42 detections, 46 tracks\n",
      "Frame  218: 42 people, 42 detections, 46 tracks\n",
      "Frame  219: 41 people, 41 detections, 46 tracks\n",
      "Frame  220: 41 people, 41 detections, 46 tracks\n",
      "Frame  221: 41 people, 41 detections, 47 tracks\n",
      "Frame  222: 41 people, 41 detections, 46 tracks\n",
      "Frame  223: 38 people, 38 detections, 45 tracks\n",
      "Frame  224: 41 people, 41 detections, 45 tracks\n",
      "Frame  225: 42 people, 42 detections, 46 tracks\n",
      "Frame  226: 38 people, 38 detections, 47 tracks\n",
      "Frame  227: 37 people, 37 detections, 45 tracks\n",
      "Frame  228: 38 people, 38 detections, 46 tracks\n",
      "Frame  229: 38 people, 38 detections, 45 tracks\n",
      "Frame  230: 38 people, 38 detections, 45 tracks\n",
      "Frame  231: 38 people, 38 detections, 46 tracks\n",
      "Frame  232: 41 people, 41 detections, 47 tracks\n",
      "Frame  233: 41 people, 41 detections, 46 tracks\n",
      "Frame  234: 40 people, 40 detections, 46 tracks\n",
      "Frame  235: 41 people, 41 detections, 48 tracks\n",
      "Frame  236: 42 people, 42 detections, 46 tracks\n",
      "Frame  237: 39 people, 39 detections, 46 tracks\n",
      "Frame  238: 39 people, 39 detections, 47 tracks\n",
      "Frame  239: 39 people, 39 detections, 47 tracks\n",
      "Frame  240: 40 people, 40 detections, 46 tracks\n",
      "Frame  241: 40 people, 40 detections, 47 tracks\n",
      "Frame  242: 39 people, 39 detections, 47 tracks\n",
      "Frame  243: 41 people, 41 detections, 48 tracks\n",
      "Frame  244: 41 people, 41 detections, 48 tracks\n",
      "Frame  245: 41 people, 41 detections, 49 tracks\n",
      "Frame  246: 43 people, 43 detections, 51 tracks\n",
      "Frame  247: 43 people, 43 detections, 53 tracks\n",
      "Frame  248: 41 people, 41 detections, 49 tracks\n",
      "Frame  249: 44 people, 44 detections, 51 tracks\n",
      "Frame  250: 43 people, 43 detections, 50 tracks\n",
      "Frame  251: 43 people, 43 detections, 50 tracks\n",
      "Frame  252: 42 people, 42 detections, 49 tracks\n",
      "Frame  253: 43 people, 43 detections, 52 tracks\n",
      "Frame  254: 39 people, 39 detections, 49 tracks\n",
      "Frame  255: 43 people, 43 detections, 50 tracks\n",
      "Frame  256: 41 people, 41 detections, 51 tracks\n",
      "Frame  257: 43 people, 43 detections, 50 tracks\n",
      "Frame  258: 42 people, 42 detections, 51 tracks\n",
      "Frame  259: 43 people, 43 detections, 52 tracks\n",
      "Frame  260: 43 people, 43 detections, 52 tracks\n",
      "Frame  261: 44 people, 44 detections, 54 tracks\n",
      "Frame  262: 45 people, 45 detections, 55 tracks\n",
      "Frame  263: 43 people, 43 detections, 54 tracks\n",
      "Frame  264: 45 people, 45 detections, 54 tracks\n",
      "Frame  265: 45 people, 45 detections, 55 tracks\n",
      "Frame  266: 45 people, 45 detections, 55 tracks\n",
      "Frame  267: 45 people, 45 detections, 55 tracks\n",
      "Frame  268: 45 people, 45 detections, 56 tracks\n",
      "Frame  269: 44 people, 44 detections, 55 tracks\n",
      "Frame  270: 43 people, 43 detections, 54 tracks\n",
      "Frame  271: 42 people, 42 detections, 54 tracks\n",
      "Frame  272: 42 people, 42 detections, 55 tracks\n",
      "Frame  273: 44 people, 44 detections, 56 tracks\n",
      "Frame  274: 43 people, 43 detections, 55 tracks\n",
      "Frame  275: 44 people, 44 detections, 54 tracks\n",
      "Frame  276: 45 people, 45 detections, 55 tracks\n",
      "Frame  277: 45 people, 45 detections, 56 tracks\n",
      "Frame  278: 48 people, 48 detections, 56 tracks\n",
      "Frame  279: 46 people, 46 detections, 55 tracks\n",
      "Frame  280: 48 people, 48 detections, 58 tracks\n",
      "Frame  281: 44 people, 44 detections, 55 tracks\n",
      "Frame  282: 43 people, 43 detections, 55 tracks\n",
      "Frame  283: 40 people, 40 detections, 55 tracks\n",
      "Frame  284: 42 people, 42 detections, 55 tracks\n",
      "Frame  285: 41 people, 41 detections, 55 tracks\n",
      "Frame  286: 44 people, 44 detections, 55 tracks\n",
      "Frame  287: 41 people, 41 detections, 54 tracks\n",
      "Frame  288: 39 people, 39 detections, 54 tracks\n",
      "Frame  289: 42 people, 42 detections, 54 tracks\n",
      "Frame  290: 41 people, 41 detections, 54 tracks\n",
      "Frame  291: 41 people, 41 detections, 54 tracks\n",
      "Frame  292: 40 people, 40 detections, 54 tracks\n",
      "Frame  293: 40 people, 40 detections, 54 tracks\n",
      "Frame  294: 42 people, 42 detections, 54 tracks\n",
      "Frame  295: 44 people, 44 detections, 54 tracks\n",
      "Frame  296: 41 people, 41 detections, 52 tracks\n",
      "Frame  297: 41 people, 41 detections, 53 tracks\n",
      "Frame  298: 41 people, 41 detections, 52 tracks\n",
      "Frame  299: 43 people, 43 detections, 53 tracks\n",
      "Frame  300: 40 people, 40 detections, 51 tracks\n",
      "Frame  301: 41 people, 41 detections, 51 tracks\n",
      "Frame  302: 43 people, 43 detections, 53 tracks\n",
      "Frame  303: 44 people, 44 detections, 54 tracks\n",
      "Frame  304: 41 people, 41 detections, 52 tracks\n",
      "Frame  305: 42 people, 42 detections, 54 tracks\n",
      "Frame  306: 46 people, 46 detections, 55 tracks\n",
      "Frame  307: 45 people, 45 detections, 54 tracks\n",
      "Frame  308: 43 people, 43 detections, 53 tracks\n",
      "Frame  309: 42 people, 42 detections, 55 tracks\n",
      "Frame  310: 41 people, 41 detections, 54 tracks\n",
      "Frame  311: 43 people, 43 detections, 55 tracks\n",
      "Frame  312: 43 people, 43 detections, 53 tracks\n",
      "Frame  313: 44 people, 44 detections, 54 tracks\n",
      "Frame  314: 43 people, 43 detections, 53 tracks\n",
      "Frame  315: 43 people, 43 detections, 54 tracks\n",
      "Frame  316: 43 people, 43 detections, 55 tracks\n",
      "Frame  317: 39 people, 39 detections, 52 tracks\n",
      "Frame  318: 43 people, 43 detections, 54 tracks\n",
      "Frame  319: 43 people, 43 detections, 54 tracks\n",
      "Frame  320: 43 people, 43 detections, 53 tracks\n",
      "Frame  321: 40 people, 40 detections, 52 tracks\n",
      "Frame  322: 44 people, 44 detections, 53 tracks\n",
      "Frame  323: 44 people, 44 detections, 52 tracks\n",
      "Frame  324: 46 people, 46 detections, 53 tracks\n",
      "Frame  325: 43 people, 43 detections, 53 tracks\n",
      "Frame  326: 44 people, 44 detections, 51 tracks\n",
      "Frame  327: 42 people, 42 detections, 51 tracks\n",
      "Frame  328: 42 people, 42 detections, 51 tracks\n",
      "Frame  329: 42 people, 42 detections, 51 tracks\n",
      "Frame  330: 44 people, 44 detections, 52 tracks\n",
      "Frame  331: 45 people, 45 detections, 52 tracks\n",
      "Frame  332: 44 people, 44 detections, 53 tracks\n",
      "Frame  333: 44 people, 44 detections, 52 tracks\n",
      "Frame  334: 47 people, 47 detections, 53 tracks\n",
      "Frame  335: 42 people, 42 detections, 52 tracks\n",
      "Frame  336: 42 people, 42 detections, 52 tracks\n",
      "Frame  337: 45 people, 45 detections, 53 tracks\n",
      "Frame  338: 45 people, 45 detections, 52 tracks\n",
      "Frame  339: 44 people, 44 detections, 51 tracks\n",
      "Frame  340: 48 people, 48 detections, 52 tracks\n",
      "Frame  341: 48 people, 48 detections, 52 tracks\n",
      "Frame  342: 47 people, 47 detections, 52 tracks\n",
      "Frame  343: 47 people, 47 detections, 53 tracks\n",
      "Frame  344: 46 people, 46 detections, 53 tracks\n",
      "Frame  345: 46 people, 46 detections, 52 tracks\n",
      "Frame  346: 47 people, 47 detections, 53 tracks\n",
      "Frame  347: 46 people, 46 detections, 51 tracks\n",
      "Frame  348: 47 people, 47 detections, 53 tracks\n",
      "Frame  349: 46 people, 46 detections, 52 tracks\n",
      "Frame  350: 47 people, 47 detections, 52 tracks\n",
      "Frame  351: 48 people, 48 detections, 53 tracks\n",
      "Frame  352: 46 people, 46 detections, 53 tracks\n",
      "Frame  353: 49 people, 49 detections, 53 tracks\n",
      "Frame  354: 47 people, 47 detections, 53 tracks\n",
      "Frame  355: 49 people, 49 detections, 53 tracks\n",
      "Frame  356: 47 people, 47 detections, 52 tracks\n",
      "Frame  357: 46 people, 46 detections, 53 tracks\n",
      "Frame  358: 45 people, 45 detections, 52 tracks\n",
      "Frame  359: 46 people, 46 detections, 53 tracks\n",
      "Frame  360: 46 people, 46 detections, 53 tracks\n",
      "Frame  361: 47 people, 47 detections, 53 tracks\n",
      "Frame  362: 49 people, 49 detections, 55 tracks\n",
      "Frame  363: 47 people, 47 detections, 53 tracks\n",
      "Frame  364: 49 people, 49 detections, 54 tracks\n",
      "Frame  365: 46 people, 46 detections, 53 tracks\n",
      "Frame  366: 46 people, 46 detections, 53 tracks\n",
      "Frame  367: 47 people, 47 detections, 54 tracks\n",
      "Frame  368: 47 people, 47 detections, 53 tracks\n",
      "Frame  369: 49 people, 49 detections, 54 tracks\n",
      "Frame  370: 47 people, 47 detections, 53 tracks\n",
      "Frame  371: 47 people, 47 detections, 53 tracks\n",
      "Frame  372: 49 people, 49 detections, 54 tracks\n",
      "Frame  373: 48 people, 48 detections, 53 tracks\n",
      "Frame  374: 48 people, 48 detections, 54 tracks\n",
      "Frame  375: 46 people, 46 detections, 53 tracks\n",
      "Frame  376: 48 people, 48 detections, 54 tracks\n",
      "Frame  377: 46 people, 46 detections, 52 tracks\n",
      "Frame  378: 49 people, 49 detections, 54 tracks\n",
      "Frame  379: 48 people, 48 detections, 53 tracks\n",
      "Frame  380: 47 people, 47 detections, 52 tracks\n",
      "Frame  381: 46 people, 46 detections, 53 tracks\n",
      "Frame  382: 48 people, 48 detections, 55 tracks\n",
      "Frame  383: 48 people, 48 detections, 54 tracks\n",
      "Frame  384: 47 people, 47 detections, 55 tracks\n",
      "Frame  385: 47 people, 47 detections, 54 tracks\n",
      "Frame  386: 45 people, 45 detections, 54 tracks\n",
      "Frame  387: 48 people, 48 detections, 57 tracks\n",
      "Frame  388: 47 people, 47 detections, 57 tracks\n",
      "Frame  389: 46 people, 46 detections, 56 tracks\n",
      "Frame  390: 46 people, 46 detections, 55 tracks\n",
      "Frame  391: 47 people, 47 detections, 56 tracks\n",
      "Frame  392: 49 people, 49 detections, 57 tracks\n",
      "Frame  393: 46 people, 46 detections, 57 tracks\n",
      "Frame  394: 46 people, 46 detections, 58 tracks\n",
      "Frame  395: 47 people, 47 detections, 61 tracks\n",
      "Frame  396: 47 people, 47 detections, 61 tracks\n",
      "Frame  397: 46 people, 46 detections, 61 tracks\n",
      "Frame  398: 46 people, 46 detections, 60 tracks\n",
      "Frame  399: 49 people, 49 detections, 60 tracks\n",
      "Frame  400: 48 people, 48 detections, 62 tracks\n",
      "Frame  401: 46 people, 46 detections, 59 tracks\n",
      "Frame  402: 46 people, 46 detections, 60 tracks\n",
      "Frame  403: 46 people, 46 detections, 60 tracks\n",
      "Frame  404: 46 people, 46 detections, 61 tracks\n",
      "Frame  405: 45 people, 45 detections, 62 tracks\n",
      "Frame  406: 48 people, 48 detections, 63 tracks\n",
      "Frame  407: 47 people, 47 detections, 61 tracks\n",
      "Frame  408: 48 people, 48 detections, 62 tracks\n",
      "Frame  409: 46 people, 46 detections, 62 tracks\n",
      "Frame  410: 46 people, 46 detections, 62 tracks\n",
      "Frame  411: 49 people, 49 detections, 64 tracks\n",
      "Frame  412: 46 people, 46 detections, 62 tracks\n",
      "Frame  413: 45 people, 45 detections, 62 tracks\n",
      "Frame  414: 44 people, 44 detections, 62 tracks\n",
      "Frame  415: 45 people, 45 detections, 62 tracks\n",
      "Frame  416: 45 people, 45 detections, 62 tracks\n",
      "Frame  417: 46 people, 46 detections, 61 tracks\n",
      "Frame  418: 45 people, 45 detections, 61 tracks\n",
      "Frame  419: 47 people, 47 detections, 63 tracks\n",
      "Frame  420: 48 people, 48 detections, 62 tracks\n",
      "Frame  421: 50 people, 50 detections, 63 tracks\n",
      "Frame  422: 49 people, 49 detections, 62 tracks\n",
      "Frame  423: 49 people, 49 detections, 60 tracks\n",
      "Frame  424: 47 people, 47 detections, 60 tracks\n",
      "Frame  425: 50 people, 50 detections, 61 tracks\n",
      "Frame  426: 52 people, 52 detections, 63 tracks\n",
      "Frame  427: 48 people, 48 detections, 62 tracks\n",
      "Frame  428: 47 people, 47 detections, 61 tracks\n",
      "Frame  429: 48 people, 48 detections, 61 tracks\n",
      "Frame  430: 47 people, 47 detections, 62 tracks\n",
      "Frame  431: 45 people, 45 detections, 61 tracks\n",
      "Frame  432: 45 people, 45 detections, 62 tracks\n",
      "Frame  433: 44 people, 44 detections, 59 tracks\n",
      "Frame  434: 49 people, 49 detections, 60 tracks\n",
      "Frame  435: 49 people, 49 detections, 60 tracks\n",
      "Frame  436: 47 people, 47 detections, 60 tracks\n",
      "Frame  437: 47 people, 47 detections, 59 tracks\n",
      "Frame  438: 49 people, 49 detections, 59 tracks\n",
      "Frame  439: 47 people, 47 detections, 58 tracks\n",
      "Frame  440: 49 people, 49 detections, 61 tracks\n",
      "Frame  441: 48 people, 48 detections, 59 tracks\n",
      "Frame  442: 47 people, 47 detections, 57 tracks\n",
      "Frame  443: 48 people, 48 detections, 58 tracks\n",
      "Frame  444: 49 people, 49 detections, 58 tracks\n",
      "Frame  445: 49 people, 49 detections, 61 tracks\n",
      "Frame  446: 51 people, 51 detections, 62 tracks\n",
      "Frame  447: 47 people, 47 detections, 61 tracks\n",
      "Frame  448: 50 people, 50 detections, 60 tracks\n",
      "Frame  449: 49 people, 49 detections, 60 tracks\n",
      "Frame  450: 47 people, 47 detections, 60 tracks\n",
      "Frame  451: 49 people, 49 detections, 61 tracks\n",
      "Frame  452: 46 people, 46 detections, 61 tracks\n",
      "Frame  453: 46 people, 46 detections, 59 tracks\n",
      "Frame  454: 49 people, 49 detections, 60 tracks\n",
      "Frame  455: 50 people, 50 detections, 61 tracks\n",
      "Frame  456: 48 people, 48 detections, 60 tracks\n",
      "Frame  457: 45 people, 45 detections, 61 tracks\n",
      "Frame  458: 43 people, 43 detections, 61 tracks\n",
      "Frame  459: 46 people, 46 detections, 61 tracks\n",
      "Frame  460: 49 people, 49 detections, 63 tracks\n",
      "Frame  461: 43 people, 43 detections, 62 tracks\n",
      "Frame  462: 44 people, 44 detections, 62 tracks\n",
      "Frame  463: 46 people, 46 detections, 63 tracks\n",
      "Frame  464: 48 people, 48 detections, 64 tracks\n",
      "Frame  465: 48 people, 48 detections, 64 tracks\n",
      "Frame  466: 46 people, 46 detections, 63 tracks\n",
      "Frame  467: 47 people, 47 detections, 62 tracks\n",
      "Frame  468: 47 people, 47 detections, 62 tracks\n",
      "Frame  469: 49 people, 49 detections, 64 tracks\n",
      "Frame  470: 43 people, 43 detections, 63 tracks\n",
      "Frame  471: 43 people, 43 detections, 63 tracks\n",
      "Frame  472: 43 people, 43 detections, 62 tracks\n",
      "Frame  473: 43 people, 43 detections, 62 tracks\n",
      "Frame  474: 42 people, 42 detections, 62 tracks\n",
      "Frame  475: 45 people, 45 detections, 62 tracks\n",
      "Frame  476: 46 people, 46 detections, 64 tracks\n",
      "Frame  477: 43 people, 43 detections, 60 tracks\n",
      "Frame  478: 44 people, 44 detections, 61 tracks\n",
      "Frame  479: 48 people, 48 detections, 64 tracks\n",
      "Frame  480: 45 people, 45 detections, 61 tracks\n",
      "Frame  481: 43 people, 43 detections, 63 tracks\n",
      "Frame  482: 45 people, 45 detections, 63 tracks\n",
      "Frame  483: 45 people, 45 detections, 63 tracks\n",
      "Frame  484: 46 people, 46 detections, 63 tracks\n",
      "Frame  485: 44 people, 44 detections, 64 tracks\n",
      "Frame  486: 45 people, 45 detections, 62 tracks\n",
      "Frame  487: 44 people, 44 detections, 62 tracks\n",
      "Frame  488: 44 people, 44 detections, 63 tracks\n",
      "Frame  489: 45 people, 45 detections, 62 tracks\n",
      "Frame  490: 43 people, 43 detections, 62 tracks\n",
      "Frame  491: 44 people, 44 detections, 61 tracks\n",
      "Frame  492: 43 people, 43 detections, 61 tracks\n",
      "Frame  493: 44 people, 44 detections, 60 tracks\n",
      "Frame  494: 41 people, 41 detections, 60 tracks\n",
      "Frame  495: 44 people, 44 detections, 60 tracks\n",
      "Frame  496: 43 people, 43 detections, 59 tracks\n",
      "Frame  497: 43 people, 43 detections, 59 tracks\n",
      "Frame  498: 43 people, 43 detections, 60 tracks\n",
      "Frame  499: 45 people, 45 detections, 58 tracks\n",
      "Frame  500: 43 people, 43 detections, 57 tracks\n",
      "Frame  501: 42 people, 42 detections, 57 tracks\n",
      "Frame  502: 44 people, 44 detections, 57 tracks\n",
      "Frame  503: 47 people, 47 detections, 58 tracks\n",
      "Frame  504: 46 people, 46 detections, 58 tracks\n",
      "Frame  505: 45 people, 45 detections, 58 tracks\n",
      "Frame  506: 41 people, 41 detections, 57 tracks\n",
      "Frame  507: 43 people, 43 detections, 58 tracks\n",
      "Frame  508: 43 people, 43 detections, 58 tracks\n",
      "Frame  509: 43 people, 43 detections, 58 tracks\n",
      "Frame  510: 45 people, 45 detections, 57 tracks\n",
      "Frame  511: 43 people, 43 detections, 55 tracks\n",
      "Frame  512: 42 people, 42 detections, 56 tracks\n",
      "Frame  513: 42 people, 42 detections, 56 tracks\n",
      "Frame  514: 42 people, 42 detections, 55 tracks\n",
      "Frame  515: 40 people, 40 detections, 55 tracks\n",
      "Frame  516: 39 people, 39 detections, 54 tracks\n",
      "Frame  517: 39 people, 39 detections, 54 tracks\n",
      "Frame  518: 42 people, 42 detections, 54 tracks\n",
      "Frame  519: 39 people, 39 detections, 52 tracks\n",
      "Frame  520: 39 people, 39 detections, 53 tracks\n",
      "Frame  521: 40 people, 40 detections, 54 tracks\n",
      "Frame  522: 38 people, 38 detections, 53 tracks\n",
      "Frame  523: 41 people, 41 detections, 55 tracks\n",
      "Frame  524: 43 people, 43 detections, 51 tracks\n",
      "Frame  525: 41 people, 41 detections, 51 tracks\n",
      "Frame  526: 41 people, 41 detections, 51 tracks\n",
      "Frame  527: 41 people, 41 detections, 50 tracks\n",
      "Frame  528: 43 people, 43 detections, 49 tracks\n",
      "Frame  529: 46 people, 46 detections, 52 tracks\n",
      "Frame  530: 47 people, 47 detections, 51 tracks\n",
      "Frame  531: 42 people, 42 detections, 50 tracks\n",
      "Frame  532: 42 people, 42 detections, 52 tracks\n",
      "Frame  533: 42 people, 42 detections, 51 tracks\n",
      "Frame  534: 41 people, 41 detections, 51 tracks\n",
      "Frame  535: 41 people, 41 detections, 51 tracks\n",
      "Frame  536: 41 people, 41 detections, 51 tracks\n",
      "Frame  537: 42 people, 42 detections, 53 tracks\n",
      "Frame  538: 41 people, 41 detections, 54 tracks\n",
      "Frame  539: 42 people, 42 detections, 54 tracks\n",
      "Frame  540: 40 people, 40 detections, 54 tracks\n",
      "Frame  541: 39 people, 39 detections, 53 tracks\n",
      "Frame  542: 37 people, 37 detections, 54 tracks\n",
      "Frame  543: 39 people, 39 detections, 54 tracks\n",
      "Frame  544: 40 people, 40 detections, 55 tracks\n",
      "Frame  545: 38 people, 38 detections, 53 tracks\n",
      "Frame  546: 38 people, 38 detections, 54 tracks\n",
      "Frame  547: 39 people, 39 detections, 54 tracks\n",
      "Frame  548: 42 people, 42 detections, 54 tracks\n",
      "Frame  549: 36 people, 36 detections, 53 tracks\n",
      "Frame  550: 38 people, 38 detections, 53 tracks\n",
      "Frame  551: 37 people, 37 detections, 53 tracks\n",
      "Frame  552: 37 people, 37 detections, 53 tracks\n",
      "Frame  553: 39 people, 39 detections, 52 tracks\n",
      "Frame  554: 38 people, 38 detections, 53 tracks\n",
      "Frame  555: 38 people, 38 detections, 53 tracks\n",
      "Frame  556: 39 people, 39 detections, 53 tracks\n",
      "Frame  557: 41 people, 41 detections, 55 tracks\n",
      "Frame  558: 38 people, 38 detections, 53 tracks\n",
      "Frame  559: 36 people, 36 detections, 54 tracks\n",
      "Frame  560: 38 people, 38 detections, 54 tracks\n",
      "Frame  561: 42 people, 42 detections, 55 tracks\n",
      "Frame  562: 40 people, 40 detections, 57 tracks\n",
      "Frame  563: 37 people, 37 detections, 54 tracks\n",
      "Frame  564: 39 people, 39 detections, 54 tracks\n",
      "Frame  565: 38 people, 38 detections, 54 tracks\n",
      "Frame  566: 38 people, 38 detections, 54 tracks\n",
      "Frame  567: 39 people, 39 detections, 54 tracks\n",
      "Frame  568: 38 people, 38 detections, 54 tracks\n",
      "Frame  569: 36 people, 36 detections, 53 tracks\n",
      "Frame  570: 37 people, 37 detections, 52 tracks\n",
      "Frame  571: 38 people, 38 detections, 53 tracks\n",
      "Frame  572: 36 people, 36 detections, 52 tracks\n",
      "Frame  573: 36 people, 36 detections, 52 tracks\n",
      "Frame  574: 39 people, 39 detections, 53 tracks\n",
      "Frame  575: 37 people, 37 detections, 53 tracks\n",
      "Frame  576: 38 people, 38 detections, 51 tracks\n",
      "Frame  577: 40 people, 40 detections, 52 tracks\n",
      "Frame  578: 39 people, 39 detections, 51 tracks\n",
      "Frame  579: 41 people, 41 detections, 50 tracks\n",
      "Frame  580: 39 people, 39 detections, 48 tracks\n",
      "Frame  581: 41 people, 41 detections, 50 tracks\n",
      "Frame  582: 40 people, 40 detections, 50 tracks\n",
      "Frame  583: 39 people, 39 detections, 49 tracks\n",
      "Frame  584: 40 people, 40 detections, 50 tracks\n",
      "Frame  585: 40 people, 40 detections, 50 tracks\n",
      "Frame  586: 37 people, 37 detections, 49 tracks\n",
      "Frame  587: 37 people, 37 detections, 50 tracks\n",
      "Frame  588: 37 people, 37 detections, 50 tracks\n",
      "Frame  589: 39 people, 39 detections, 50 tracks\n",
      "Frame  590: 37 people, 37 detections, 50 tracks\n",
      "Frame  591: 38 people, 38 detections, 51 tracks\n",
      "Frame  592: 36 people, 36 detections, 49 tracks\n",
      "Frame  593: 39 people, 39 detections, 50 tracks\n",
      "Frame  594: 40 people, 40 detections, 50 tracks\n",
      "Frame  595: 37 people, 37 detections, 50 tracks\n",
      "Frame  596: 37 people, 37 detections, 50 tracks\n",
      "Frame  597: 39 people, 39 detections, 53 tracks\n",
      "Frame  598: 38 people, 38 detections, 51 tracks\n",
      "Frame  599: 37 people, 37 detections, 50 tracks\n",
      "Frame  600: 39 people, 39 detections, 50 tracks\n",
      "Frame  601: 35 people, 35 detections, 50 tracks\n",
      "Frame  602: 37 people, 37 detections, 50 tracks\n",
      "Frame  603: 37 people, 37 detections, 51 tracks\n",
      "Frame  604: 38 people, 38 detections, 50 tracks\n",
      "Frame  605: 40 people, 40 detections, 51 tracks\n",
      "Frame  606: 41 people, 41 detections, 52 tracks\n",
      "Frame  607: 40 people, 40 detections, 51 tracks\n",
      "Frame  608: 41 people, 41 detections, 52 tracks\n",
      "Frame  609: 42 people, 42 detections, 51 tracks\n",
      "Frame  610: 43 people, 43 detections, 52 tracks\n",
      "Frame  611: 43 people, 43 detections, 52 tracks\n",
      "Frame  612: 43 people, 43 detections, 52 tracks\n",
      "Frame  613: 42 people, 42 detections, 52 tracks\n",
      "Frame  614: 40 people, 40 detections, 52 tracks\n",
      "Frame  615: 39 people, 39 detections, 52 tracks\n",
      "Frame  616: 37 people, 37 detections, 51 tracks\n",
      "Frame  617: 40 people, 40 detections, 51 tracks\n",
      "Frame  618: 40 people, 40 detections, 51 tracks\n",
      "Frame  619: 43 people, 43 detections, 54 tracks\n",
      "Frame  620: 42 people, 42 detections, 52 tracks\n",
      "Frame  621: 43 people, 43 detections, 54 tracks\n",
      "Frame  622: 41 people, 41 detections, 53 tracks\n",
      "Frame  623: 40 people, 40 detections, 53 tracks\n",
      "Frame  624: 41 people, 41 detections, 53 tracks\n",
      "Frame  625: 40 people, 40 detections, 53 tracks\n",
      "Frame  626: 41 people, 41 detections, 54 tracks\n",
      "Frame  627: 39 people, 39 detections, 53 tracks\n",
      "Frame  628: 39 people, 39 detections, 52 tracks\n",
      "Frame  629: 41 people, 41 detections, 55 tracks\n",
      "Frame  630: 40 people, 40 detections, 54 tracks\n",
      "Frame  631: 40 people, 40 detections, 53 tracks\n",
      "Frame  632: 39 people, 39 detections, 53 tracks\n",
      "Frame  633: 40 people, 40 detections, 54 tracks\n",
      "Frame  634: 41 people, 41 detections, 55 tracks\n",
      "Frame  635: 41 people, 41 detections, 54 tracks\n",
      "Frame  636: 39 people, 39 detections, 56 tracks\n",
      "Frame  637: 40 people, 40 detections, 55 tracks\n",
      "Frame  638: 41 people, 41 detections, 56 tracks\n",
      "Frame  639: 41 people, 41 detections, 56 tracks\n",
      "Frame  640: 38 people, 38 detections, 56 tracks\n",
      "Frame  641: 36 people, 36 detections, 56 tracks\n",
      "Frame  642: 43 people, 43 detections, 56 tracks\n",
      "Frame  643: 40 people, 40 detections, 55 tracks\n",
      "Frame  644: 40 people, 40 detections, 54 tracks\n",
      "Frame  645: 40 people, 40 detections, 55 tracks\n",
      "Frame  646: 42 people, 42 detections, 54 tracks\n",
      "Frame  647: 42 people, 42 detections, 55 tracks\n",
      "Frame  648: 38 people, 38 detections, 54 tracks\n",
      "Frame  649: 38 people, 38 detections, 54 tracks\n",
      "Frame  650: 38 people, 38 detections, 55 tracks\n",
      "Frame  651: 37 people, 37 detections, 54 tracks\n",
      "Frame  652: 37 people, 37 detections, 54 tracks\n",
      "Frame  653: 34 people, 34 detections, 53 tracks\n",
      "Frame  654: 35 people, 35 detections, 53 tracks\n",
      "Frame  655: 36 people, 36 detections, 53 tracks\n",
      "Frame  656: 37 people, 37 detections, 54 tracks\n",
      "Frame  657: 36 people, 36 detections, 55 tracks\n",
      "Frame  658: 40 people, 40 detections, 55 tracks\n",
      "Frame  659: 36 people, 36 detections, 53 tracks\n",
      "Frame  660: 34 people, 34 detections, 54 tracks\n",
      "Frame  661: 35 people, 35 detections, 54 tracks\n",
      "Frame  662: 35 people, 35 detections, 54 tracks\n",
      "Frame  663: 34 people, 34 detections, 54 tracks\n",
      "Frame  664: 34 people, 34 detections, 54 tracks\n",
      "Frame  665: 33 people, 33 detections, 52 tracks\n",
      "Frame  666: 35 people, 35 detections, 51 tracks\n",
      "Frame  667: 38 people, 38 detections, 52 tracks\n",
      "Frame  668: 38 people, 38 detections, 54 tracks\n",
      "Frame  669: 37 people, 37 detections, 53 tracks\n",
      "Frame  670: 41 people, 41 detections, 53 tracks\n",
      "Frame  671: 39 people, 39 detections, 52 tracks\n",
      "Frame  672: 39 people, 39 detections, 52 tracks\n",
      "Frame  673: 37 people, 37 detections, 51 tracks\n",
      "Frame  674: 36 people, 36 detections, 52 tracks\n",
      "Frame  675: 36 people, 36 detections, 50 tracks\n",
      "Frame  676: 35 people, 35 detections, 50 tracks\n",
      "Frame  677: 35 people, 35 detections, 50 tracks\n",
      "Frame  678: 36 people, 36 detections, 49 tracks\n",
      "Frame  679: 37 people, 37 detections, 50 tracks\n",
      "Frame  680: 39 people, 39 detections, 51 tracks\n",
      "Frame  681: 37 people, 37 detections, 50 tracks\n",
      "Frame  682: 37 people, 37 detections, 50 tracks\n",
      "Frame  683: 39 people, 39 detections, 50 tracks\n",
      "Frame  684: 37 people, 37 detections, 50 tracks\n",
      "Frame  685: 36 people, 36 detections, 48 tracks\n",
      "Frame  686: 37 people, 37 detections, 49 tracks\n",
      "Frame  687: 35 people, 35 detections, 48 tracks\n",
      "Frame  688: 36 people, 36 detections, 48 tracks\n",
      "Frame  689: 35 people, 35 detections, 47 tracks\n",
      "Frame  690: 36 people, 36 detections, 47 tracks\n",
      "Frame  691: 35 people, 35 detections, 46 tracks\n",
      "Frame  692: 38 people, 38 detections, 47 tracks\n",
      "Frame  693: 41 people, 41 detections, 48 tracks\n",
      "Frame  694: 40 people, 40 detections, 48 tracks\n",
      "Frame  695: 37 people, 37 detections, 46 tracks\n",
      "Frame  696: 35 people, 35 detections, 46 tracks\n",
      "Frame  697: 36 people, 36 detections, 46 tracks\n",
      "Frame  698: 37 people, 37 detections, 48 tracks\n",
      "Frame  699: 35 people, 35 detections, 48 tracks\n",
      "Frame  700: 35 people, 35 detections, 48 tracks\n",
      "Frame  701: 36 people, 36 detections, 47 tracks\n",
      "Frame  702: 36 people, 36 detections, 47 tracks\n",
      "Frame  703: 36 people, 36 detections, 48 tracks\n",
      "Frame  704: 38 people, 38 detections, 48 tracks\n",
      "Frame  705: 36 people, 36 detections, 49 tracks\n",
      "Frame  706: 36 people, 36 detections, 49 tracks\n",
      "Frame  707: 36 people, 36 detections, 50 tracks\n",
      "Frame  708: 37 people, 37 detections, 49 tracks\n",
      "Frame  709: 37 people, 37 detections, 49 tracks\n",
      "Frame  710: 39 people, 39 detections, 51 tracks\n",
      "Frame  711: 36 people, 36 detections, 50 tracks\n",
      "Frame  712: 36 people, 36 detections, 50 tracks\n",
      "Frame  713: 36 people, 36 detections, 50 tracks\n",
      "Frame  714: 38 people, 38 detections, 50 tracks\n",
      "Frame  715: 34 people, 34 detections, 50 tracks\n",
      "Frame  716: 35 people, 35 detections, 48 tracks\n",
      "Frame  717: 37 people, 37 detections, 48 tracks\n",
      "Frame  718: 39 people, 39 detections, 47 tracks\n",
      "Frame  719: 37 people, 37 detections, 48 tracks\n",
      "Frame  720: 35 people, 35 detections, 47 tracks\n",
      "Frame  721: 40 people, 40 detections, 49 tracks\n",
      "Frame  722: 38 people, 38 detections, 48 tracks\n",
      "Frame  723: 42 people, 42 detections, 51 tracks\n",
      "Frame  724: 38 people, 38 detections, 50 tracks\n",
      "Frame  725: 37 people, 37 detections, 49 tracks\n",
      "Frame  726: 40 people, 40 detections, 48 tracks\n",
      "Frame  727: 41 people, 41 detections, 48 tracks\n",
      "Frame  728: 39 people, 39 detections, 48 tracks\n",
      "Frame  729: 39 people, 39 detections, 47 tracks\n",
      "Frame  730: 41 people, 41 detections, 49 tracks\n",
      "Frame  731: 39 people, 39 detections, 49 tracks\n",
      "Frame  732: 38 people, 38 detections, 48 tracks\n",
      "Frame  733: 39 people, 39 detections, 49 tracks\n",
      "Frame  734: 37 people, 37 detections, 49 tracks\n",
      "Frame  735: 38 people, 38 detections, 47 tracks\n",
      "Frame  736: 41 people, 41 detections, 50 tracks\n",
      "Frame  737: 36 people, 36 detections, 49 tracks\n",
      "Frame  738: 34 people, 34 detections, 48 tracks\n",
      "Frame  739: 35 people, 35 detections, 48 tracks\n",
      "Frame  740: 35 people, 35 detections, 48 tracks\n",
      "Frame  741: 35 people, 35 detections, 47 tracks\n",
      "Frame  742: 35 people, 35 detections, 49 tracks\n",
      "Frame  743: 39 people, 39 detections, 49 tracks\n",
      "Frame  744: 32 people, 32 detections, 47 tracks\n",
      "Frame  745: 39 people, 39 detections, 48 tracks\n",
      "Frame  746: 35 people, 35 detections, 46 tracks\n",
      "Frame  747: 35 people, 35 detections, 47 tracks\n",
      "Frame  748: 34 people, 34 detections, 47 tracks\n",
      "Frame  749: 33 people, 33 detections, 47 tracks\n",
      "Frame  750: 32 people, 32 detections, 47 tracks\n",
      "Frame  751: 31 people, 31 detections, 47 tracks\n",
      "Frame  752: 32 people, 32 detections, 46 tracks\n",
      "Frame  753: 35 people, 35 detections, 47 tracks\n",
      "Frame  754: 33 people, 33 detections, 46 tracks\n",
      "Frame  755: 33 people, 33 detections, 47 tracks\n",
      "Frame  756: 30 people, 30 detections, 47 tracks\n",
      "Frame  757: 34 people, 34 detections, 47 tracks\n",
      "Frame  758: 34 people, 34 detections, 47 tracks\n",
      "Frame  759: 35 people, 35 detections, 47 tracks\n",
      "Frame  760: 31 people, 31 detections, 48 tracks\n",
      "Frame  761: 32 people, 32 detections, 47 tracks\n",
      "Frame  762: 34 people, 34 detections, 48 tracks\n",
      "Frame  763: 36 people, 36 detections, 49 tracks\n",
      "Frame  764: 35 people, 35 detections, 48 tracks\n",
      "Frame  765: 35 people, 35 detections, 50 tracks\n",
      "Frame  766: 37 people, 37 detections, 50 tracks\n",
      "Frame  767: 37 people, 37 detections, 49 tracks\n",
      "Frame  768: 34 people, 34 detections, 50 tracks\n",
      "Frame  769: 37 people, 37 detections, 54 tracks\n",
      "Frame  770: 36 people, 36 detections, 54 tracks\n",
      "Frame  771: 35 people, 35 detections, 52 tracks\n",
      "Frame  772: 37 people, 37 detections, 54 tracks\n",
      "Frame  773: 36 people, 36 detections, 54 tracks\n",
      "Frame  774: 39 people, 39 detections, 56 tracks\n",
      "Frame  775: 36 people, 36 detections, 54 tracks\n",
      "Frame  776: 36 people, 36 detections, 55 tracks\n",
      "Frame  777: 36 people, 36 detections, 57 tracks\n",
      "Frame  778: 37 people, 37 detections, 55 tracks\n",
      "Frame  779: 34 people, 34 detections, 54 tracks\n",
      "Frame  780: 36 people, 36 detections, 53 tracks\n",
      "Frame  781: 35 people, 35 detections, 54 tracks\n",
      "Frame  782: 38 people, 38 detections, 54 tracks\n",
      "Frame  783: 35 people, 35 detections, 55 tracks\n",
      "Frame  784: 35 people, 35 detections, 53 tracks\n",
      "Frame  785: 35 people, 35 detections, 54 tracks\n",
      "Frame  786: 35 people, 35 detections, 53 tracks\n",
      "Frame  787: 39 people, 39 detections, 53 tracks\n",
      "Frame  788: 40 people, 40 detections, 53 tracks\n",
      "Frame  789: 39 people, 39 detections, 53 tracks\n",
      "Frame  790: 39 people, 39 detections, 52 tracks\n",
      "Frame  791: 42 people, 42 detections, 56 tracks\n",
      "Frame  792: 39 people, 39 detections, 54 tracks\n",
      "Frame  793: 36 people, 36 detections, 53 tracks\n",
      "Frame  794: 41 people, 41 detections, 54 tracks\n",
      "Frame  795: 39 people, 39 detections, 54 tracks\n",
      "Frame  796: 39 people, 39 detections, 53 tracks\n",
      "Frame  797: 40 people, 40 detections, 54 tracks\n",
      "Frame  798: 39 people, 39 detections, 51 tracks\n",
      "Frame  799: 39 people, 39 detections, 50 tracks\n",
      "Frame  800: 39 people, 39 detections, 50 tracks\n",
      "Frame  801: 40 people, 40 detections, 49 tracks\n",
      "Frame  802: 38 people, 38 detections, 49 tracks\n",
      "Frame  803: 37 people, 37 detections, 50 tracks\n",
      "Frame  804: 36 people, 36 detections, 50 tracks\n",
      "Frame  805: 38 people, 38 detections, 50 tracks\n",
      "Frame  806: 36 people, 36 detections, 50 tracks\n",
      "Frame  807: 35 people, 35 detections, 50 tracks\n",
      "Frame  808: 38 people, 38 detections, 51 tracks\n",
      "Frame  809: 35 people, 35 detections, 50 tracks\n",
      "Frame  810: 36 people, 36 detections, 50 tracks\n",
      "Frame  811: 40 people, 40 detections, 53 tracks\n",
      "Frame  812: 39 people, 39 detections, 52 tracks\n",
      "Frame  813: 36 people, 36 detections, 51 tracks\n",
      "Frame  814: 37 people, 37 detections, 51 tracks\n",
      "Frame  815: 36 people, 36 detections, 51 tracks\n",
      "Frame  816: 38 people, 38 detections, 51 tracks\n",
      "Frame  817: 39 people, 39 detections, 51 tracks\n",
      "Frame  818: 36 people, 36 detections, 51 tracks\n",
      "Frame  819: 38 people, 38 detections, 51 tracks\n",
      "Frame  820: 38 people, 38 detections, 53 tracks\n",
      "Frame  821: 38 people, 38 detections, 53 tracks\n",
      "Frame  822: 32 people, 32 detections, 51 tracks\n",
      "Frame  823: 35 people, 35 detections, 52 tracks\n",
      "Frame  824: 32 people, 32 detections, 50 tracks\n",
      "Frame  825: 35 people, 35 detections, 50 tracks\n",
      "Frame  826: 37 people, 37 detections, 50 tracks\n",
      "Frame  827: 37 people, 37 detections, 49 tracks\n",
      "Frame  828: 37 people, 37 detections, 50 tracks\n",
      "Frame  829: 36 people, 36 detections, 49 tracks\n",
      "Frame  830: 38 people, 38 detections, 51 tracks\n",
      "Frame  831: 39 people, 39 detections, 49 tracks\n",
      "Frame  832: 42 people, 42 detections, 50 tracks\n",
      "Frame  833: 40 people, 40 detections, 47 tracks\n",
      "Frame  834: 36 people, 36 detections, 47 tracks\n",
      "Frame  835: 37 people, 37 detections, 46 tracks\n",
      "Frame  836: 39 people, 39 detections, 48 tracks\n",
      "Frame  837: 41 people, 41 detections, 49 tracks\n",
      "Frame  838: 40 people, 40 detections, 47 tracks\n",
      "Frame  839: 38 people, 38 detections, 47 tracks\n",
      "Frame  840: 38 people, 38 detections, 48 tracks\n",
      "Frame  841: 39 people, 39 detections, 46 tracks\n",
      "Frame  842: 36 people, 36 detections, 45 tracks\n",
      "Frame  843: 36 people, 36 detections, 45 tracks\n",
      "Frame  844: 40 people, 40 detections, 47 tracks\n",
      "Frame  845: 41 people, 41 detections, 48 tracks\n",
      "Frame  846: 39 people, 39 detections, 46 tracks\n",
      "Frame  847: 40 people, 40 detections, 46 tracks\n",
      "Frame  848: 38 people, 38 detections, 45 tracks\n",
      "Frame  849: 39 people, 39 detections, 46 tracks\n",
      "Frame  850: 40 people, 40 detections, 47 tracks\n",
      "Frame  851: 37 people, 37 detections, 47 tracks\n",
      "Frame  852: 40 people, 40 detections, 47 tracks\n",
      "Frame  853: 40 people, 40 detections, 47 tracks\n",
      "Frame  854: 39 people, 39 detections, 47 tracks\n",
      "Frame  855: 37 people, 37 detections, 48 tracks\n",
      "Frame  856: 36 people, 36 detections, 46 tracks\n",
      "Frame  857: 37 people, 37 detections, 45 tracks\n",
      "Frame  858: 38 people, 38 detections, 45 tracks\n",
      "Frame  859: 34 people, 34 detections, 45 tracks\n",
      "Frame  860: 38 people, 38 detections, 46 tracks\n",
      "Frame  861: 35 people, 35 detections, 44 tracks\n",
      "Frame  862: 37 people, 37 detections, 44 tracks\n",
      "Frame  863: 36 people, 36 detections, 45 tracks\n",
      "Frame  864: 38 people, 38 detections, 46 tracks\n",
      "Frame  865: 36 people, 36 detections, 45 tracks\n",
      "Frame  866: 37 people, 37 detections, 45 tracks\n",
      "Frame  867: 37 people, 37 detections, 46 tracks\n",
      "Frame  868: 38 people, 38 detections, 45 tracks\n",
      "Frame  869: 38 people, 38 detections, 46 tracks\n",
      "Frame  870: 38 people, 38 detections, 45 tracks\n",
      "Frame  871: 36 people, 36 detections, 45 tracks\n",
      "Frame  872: 39 people, 39 detections, 47 tracks\n",
      "Frame  873: 37 people, 37 detections, 45 tracks\n",
      "Frame  874: 40 people, 40 detections, 47 tracks\n",
      "Frame  875: 38 people, 38 detections, 46 tracks\n",
      "Frame  876: 39 people, 39 detections, 46 tracks\n",
      "Frame  877: 39 people, 39 detections, 46 tracks\n",
      "Frame  878: 38 people, 38 detections, 47 tracks\n",
      "Frame  879: 41 people, 41 detections, 48 tracks\n",
      "Frame  880: 38 people, 38 detections, 47 tracks\n",
      "Frame  881: 40 people, 40 detections, 48 tracks\n",
      "Frame  882: 43 people, 43 detections, 49 tracks\n",
      "Frame  883: 43 people, 43 detections, 47 tracks\n",
      "Frame  884: 41 people, 41 detections, 47 tracks\n",
      "Frame  885: 41 people, 41 detections, 47 tracks\n",
      "Frame  886: 39 people, 39 detections, 48 tracks\n",
      "Frame  887: 40 people, 40 detections, 48 tracks\n",
      "Frame  888: 40 people, 40 detections, 48 tracks\n",
      "Frame  889: 45 people, 45 detections, 50 tracks\n",
      "Frame  890: 43 people, 43 detections, 49 tracks\n",
      "Frame  891: 40 people, 40 detections, 49 tracks\n",
      "Frame  892: 41 people, 41 detections, 48 tracks\n",
      "Frame  893: 42 people, 42 detections, 50 tracks\n",
      "Frame  894: 41 people, 41 detections, 50 tracks\n",
      "Frame  895: 40 people, 40 detections, 49 tracks\n",
      "Frame  896: 43 people, 43 detections, 50 tracks\n",
      "Frame  897: 44 people, 44 detections, 50 tracks\n",
      "Frame  898: 42 people, 42 detections, 50 tracks\n",
      "Frame  899: 42 people, 42 detections, 51 tracks\n",
      "Frame  900: 41 people, 41 detections, 52 tracks\n",
      "Frame  901: 38 people, 38 detections, 50 tracks\n",
      "Frame  902: 40 people, 40 detections, 50 tracks\n",
      "Frame  903: 40 people, 40 detections, 51 tracks\n",
      "Frame  904: 40 people, 40 detections, 50 tracks\n",
      "Frame  905: 40 people, 40 detections, 50 tracks\n",
      "Frame  906: 39 people, 39 detections, 49 tracks\n",
      "Frame  907: 43 people, 43 detections, 49 tracks\n",
      "Frame  908: 41 people, 41 detections, 50 tracks\n",
      "Frame  909: 42 people, 42 detections, 49 tracks\n",
      "Frame  910: 44 people, 44 detections, 51 tracks\n",
      "Frame  911: 42 people, 42 detections, 50 tracks\n",
      "Frame  912: 42 people, 42 detections, 50 tracks\n",
      "Frame  913: 43 people, 43 detections, 50 tracks\n",
      "Frame  914: 41 people, 41 detections, 49 tracks\n",
      "Frame  915: 44 people, 44 detections, 50 tracks\n",
      "Frame  916: 41 people, 41 detections, 50 tracks\n",
      "Frame  917: 39 people, 39 detections, 48 tracks\n",
      "Frame  918: 40 people, 40 detections, 48 tracks\n",
      "Frame  919: 41 people, 41 detections, 51 tracks\n",
      "Frame  920: 42 people, 42 detections, 51 tracks\n",
      "Frame  921: 41 people, 41 detections, 51 tracks\n",
      "Frame  922: 42 people, 42 detections, 51 tracks\n",
      "Frame  923: 42 people, 42 detections, 51 tracks\n",
      "Frame  924: 41 people, 41 detections, 51 tracks\n",
      "Frame  925: 48 people, 48 detections, 54 tracks\n",
      "Frame  926: 42 people, 42 detections, 50 tracks\n",
      "Frame  927: 39 people, 39 detections, 50 tracks\n",
      "Frame  928: 45 people, 45 detections, 50 tracks\n",
      "Frame  929: 42 people, 42 detections, 50 tracks\n",
      "Frame  930: 48 people, 48 detections, 53 tracks\n",
      "Frame  931: 45 people, 45 detections, 53 tracks\n",
      "Frame  932: 42 people, 42 detections, 50 tracks\n",
      "Frame  933: 41 people, 41 detections, 50 tracks\n",
      "Frame  934: 44 people, 44 detections, 50 tracks\n",
      "Frame  935: 42 people, 42 detections, 49 tracks\n",
      "Frame  936: 41 people, 41 detections, 49 tracks\n",
      "Frame  937: 40 people, 40 detections, 49 tracks\n",
      "Frame  938: 39 people, 39 detections, 50 tracks\n",
      "Frame  939: 40 people, 40 detections, 50 tracks\n",
      "Frame  940: 40 people, 40 detections, 50 tracks\n",
      "Frame  941: 45 people, 45 detections, 51 tracks\n",
      "Frame  942: 42 people, 42 detections, 50 tracks\n",
      "Frame  943: 44 people, 44 detections, 51 tracks\n",
      "Frame  944: 45 people, 45 detections, 52 tracks\n",
      "Frame  945: 44 people, 44 detections, 51 tracks\n",
      "Frame  946: 42 people, 42 detections, 51 tracks\n",
      "Frame  947: 46 people, 46 detections, 53 tracks\n",
      "Frame  948: 44 people, 44 detections, 51 tracks\n",
      "Frame  949: 44 people, 44 detections, 52 tracks\n",
      "Frame  950: 43 people, 43 detections, 52 tracks\n",
      "Frame  951: 46 people, 46 detections, 53 tracks\n",
      "Frame  952: 47 people, 47 detections, 53 tracks\n",
      "Frame  953: 46 people, 46 detections, 53 tracks\n",
      "Frame  954: 43 people, 43 detections, 52 tracks\n",
      "Frame  955: 46 people, 46 detections, 52 tracks\n",
      "Frame  956: 48 people, 48 detections, 52 tracks\n",
      "Frame  957: 48 people, 48 detections, 52 tracks\n",
      "Frame  958: 49 people, 49 detections, 53 tracks\n",
      "Frame  959: 44 people, 44 detections, 53 tracks\n",
      "Frame  960: 45 people, 45 detections, 54 tracks\n",
      "Frame  961: 45 people, 45 detections, 52 tracks\n",
      "Frame  962: 49 people, 49 detections, 55 tracks\n",
      "Frame  963: 46 people, 46 detections, 54 tracks\n",
      "Frame  964: 50 people, 50 detections, 56 tracks\n",
      "Frame  965: 49 people, 49 detections, 57 tracks\n",
      "Frame  966: 47 people, 47 detections, 56 tracks\n",
      "Frame  967: 50 people, 50 detections, 56 tracks\n",
      "Frame  968: 46 people, 46 detections, 56 tracks\n",
      "Frame  969: 46 people, 46 detections, 56 tracks\n",
      "Frame  970: 50 people, 50 detections, 59 tracks\n",
      "Frame  971: 49 people, 49 detections, 58 tracks\n",
      "Frame  972: 46 people, 46 detections, 57 tracks\n",
      "Frame  973: 43 people, 43 detections, 56 tracks\n",
      "Frame  974: 45 people, 45 detections, 56 tracks\n",
      "Frame  975: 44 people, 44 detections, 56 tracks\n",
      "Frame  976: 47 people, 47 detections, 58 tracks\n",
      "Frame  977: 43 people, 43 detections, 56 tracks\n",
      "Frame  978: 46 people, 46 detections, 56 tracks\n",
      "Frame  979: 45 people, 45 detections, 56 tracks\n",
      "Frame  980: 47 people, 47 detections, 57 tracks\n",
      "Frame  981: 43 people, 43 detections, 56 tracks\n",
      "Frame  982: 45 people, 45 detections, 59 tracks\n",
      "Frame  983: 44 people, 44 detections, 57 tracks\n",
      "Frame  984: 39 people, 39 detections, 57 tracks\n",
      "Frame  985: 42 people, 42 detections, 57 tracks\n",
      "Frame  986: 44 people, 44 detections, 58 tracks\n",
      "Frame  987: 44 people, 44 detections, 58 tracks\n",
      "Frame  988: 44 people, 44 detections, 58 tracks\n",
      "Frame  989: 43 people, 43 detections, 58 tracks\n",
      "Frame  990: 44 people, 44 detections, 58 tracks\n",
      "Frame  991: 45 people, 45 detections, 60 tracks\n",
      "Frame  992: 45 people, 45 detections, 57 tracks\n",
      "Frame  993: 43 people, 43 detections, 57 tracks\n",
      "Frame  994: 47 people, 47 detections, 57 tracks\n",
      "Frame  995: 48 people, 48 detections, 59 tracks\n",
      "Frame  996: 52 people, 52 detections, 61 tracks\n",
      "Frame  997: 49 people, 49 detections, 61 tracks\n",
      "Frame  998: 51 people, 51 detections, 60 tracks\n",
      "Frame  999: 52 people, 52 detections, 62 tracks\n",
      "Frame 1000: 48 people, 48 detections, 62 tracks\n",
      "Frame 1001: 47 people, 47 detections, 60 tracks\n",
      "Frame 1002: 52 people, 52 detections, 62 tracks\n",
      "Frame 1003: 50 people, 50 detections, 64 tracks\n",
      "Frame 1004: 50 people, 50 detections, 61 tracks\n",
      "Frame 1005: 49 people, 49 detections, 62 tracks\n",
      "Frame 1006: 45 people, 45 detections, 62 tracks\n",
      "Frame 1007: 47 people, 47 detections, 63 tracks\n",
      "Frame 1008: 46 people, 46 detections, 63 tracks\n",
      "Frame 1009: 50 people, 50 detections, 64 tracks\n",
      "Frame 1010: 47 people, 47 detections, 64 tracks\n",
      "Frame 1011: 46 people, 46 detections, 64 tracks\n",
      "Frame 1012: 46 people, 46 detections, 65 tracks\n",
      "Frame 1013: 45 people, 45 detections, 64 tracks\n",
      "Frame 1014: 48 people, 48 detections, 65 tracks\n",
      "Frame 1015: 46 people, 46 detections, 65 tracks\n",
      "Frame 1016: 44 people, 44 detections, 64 tracks\n",
      "Frame 1017: 48 people, 48 detections, 64 tracks\n",
      "Frame 1018: 51 people, 51 detections, 65 tracks\n",
      "Frame 1019: 51 people, 51 detections, 66 tracks\n",
      "Frame 1020: 51 people, 51 detections, 65 tracks\n",
      "Frame 1021: 53 people, 53 detections, 66 tracks\n",
      "Frame 1022: 50 people, 50 detections, 65 tracks\n",
      "Frame 1023: 49 people, 49 detections, 65 tracks\n",
      "Frame 1024: 49 people, 49 detections, 65 tracks\n",
      "Frame 1025: 49 people, 49 detections, 65 tracks\n",
      "Frame 1026: 48 people, 48 detections, 66 tracks\n",
      "Frame 1027: 51 people, 51 detections, 65 tracks\n",
      "Frame 1028: 48 people, 48 detections, 66 tracks\n",
      "Frame 1029: 51 people, 51 detections, 67 tracks\n",
      "Frame 1030: 46 people, 46 detections, 68 tracks\n",
      "Frame 1031: 50 people, 50 detections, 67 tracks\n",
      "Frame 1032: 52 people, 52 detections, 69 tracks\n",
      "Frame 1033: 50 people, 50 detections, 69 tracks\n",
      "Frame 1034: 48 people, 48 detections, 67 tracks\n",
      "Frame 1035: 48 people, 48 detections, 67 tracks\n",
      "Frame 1036: 48 people, 48 detections, 65 tracks\n",
      "Frame 1037: 50 people, 50 detections, 66 tracks\n",
      "Frame 1038: 51 people, 51 detections, 67 tracks\n",
      "Frame 1039: 50 people, 50 detections, 66 tracks\n",
      "Frame 1040: 48 people, 48 detections, 68 tracks\n",
      "Frame 1041: 47 people, 47 detections, 68 tracks\n",
      "Frame 1042: 49 people, 49 detections, 68 tracks\n",
      "Frame 1043: 52 people, 52 detections, 70 tracks\n",
      "Frame 1044: 48 people, 48 detections, 71 tracks\n",
      "Frame 1045: 49 people, 49 detections, 72 tracks\n",
      "Frame 1046: 49 people, 49 detections, 72 tracks\n",
      "Frame 1047: 44 people, 44 detections, 71 tracks\n",
      "Frame 1048: 46 people, 46 detections, 72 tracks\n",
      "Frame 1049: 48 people, 48 detections, 73 tracks\n",
      "Frame 1050: 48 people, 48 detections, 71 tracks\n",
      "\n",
      "Saved input video to   task2_input.mp4\n",
      "Saved tracked video to task2.mp4\n",
      "Saved tracks to        task2_tracks.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4.1 Task2: Faster R-CNN + DeepSORT on Task2 images\n",
    "#     - Preprocess frames\n",
    "#     - Build input video (task2_input.mp4)\n",
    "#     - Build tracked video (task2.mp4)\n",
    "#     - Save tracking results (task2_tracks.txt)\n",
    "#     - Return per-frame counts for CSV\n",
    "# ============================================\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "\n",
    "# We already have cv2, np, DeepSort imported earlier in the notebook.\n",
    "\n",
    "# Task2-specific settings (tune these if you like)\n",
    "DEVICE_T2       = \"cuda\"   # will fall back to CPU if CUDA not available\n",
    "FPS_TASK2       = 14.0     # or reuse your existing FPS_TASK2 variable\n",
    "SCORE_THRESH_T2 = 0.50     # detector score threshold\n",
    "\n",
    "# Paths for Task2 (override or reuse if already defined)\n",
    "TASK2_INPUT_VIDEO  = Path(\"task2_input.mp4\")\n",
    "TASK2_TRACKS_TXT   = Path(\"task2_tracks.txt\")\n",
    "# TASK2_IMAGES_DIR and TASK2_OUTPUT_VIDEO and TASK2_COUNTS_CSV\n",
    "# should already be defined earlier in your notebook.\n",
    "\n",
    "\n",
    "def load_frcnn_detector(device: str = DEVICE_T2):\n",
    "    \"\"\"\n",
    "    Load a Faster R-CNN ResNet50 FPN v2 detector with COCO weights.\n",
    "    \"\"\"\n",
    "    if device == \"cuda\" and not torch.cuda.is_available():\n",
    "        print(\"CUDA requested but not available, falling back to CPU.\")\n",
    "        device = \"cpu\"\n",
    "\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, device\n",
    "\n",
    "\n",
    "def init_deepsort_task2():\n",
    "    \"\"\"\n",
    "    Initialize DeepSort tracker for Task2.\n",
    "    \"\"\"\n",
    "    tracker = DeepSort(\n",
    "        max_age=30,\n",
    "        n_init=3,\n",
    "        max_iou_distance=0.7,\n",
    "        nms_max_overlap=1.0,\n",
    "        max_cosine_distance=0.2,\n",
    "        embedder=\"mobilenet\",\n",
    "        half=True,\n",
    "        bgr=True,\n",
    "        embedder_gpu=True,\n",
    "    )\n",
    "    return tracker\n",
    "\n",
    "\n",
    "def preprocess_frame(frame_bgr):\n",
    "    \"\"\"\n",
    "    Darken bright regions and sharpen the image to help detector.\n",
    "    \"\"\"\n",
    "    # 1) Darken highlights using gamma on V channel in HSV\n",
    "    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    v_float = v.astype(np.float32) / 255.0\n",
    "    gamma = 1.4\n",
    "    v_gamma = np.power(v_float, gamma)\n",
    "    v_new = np.clip(v_gamma * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    hsv = cv2.merge([h, s, v_new])\n",
    "    img_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # 2) Stronger sharpening (unsharp mask)\n",
    "    sigma = 1.2\n",
    "    amount = 1.8\n",
    "    blurred = cv2.GaussianBlur(img_bgr, (0, 0), sigma)\n",
    "    sharp = cv2.addWeighted(img_bgr, 1.0 + amount, blurred, -amount, 0)\n",
    "\n",
    "    return sharp\n",
    "\n",
    "\n",
    "def process_task2_frames(\n",
    "    frames_dir: Path,\n",
    "    input_video_path: Path,\n",
    "    tracked_video_path: Path,\n",
    "    tracks_txt_path: Path,\n",
    "    fps: float = FPS_TASK2,\n",
    "    device: str = DEVICE_T2,\n",
    "    score_thresh: float = SCORE_THRESH_T2,\n",
    "):\n",
    "    \"\"\"\n",
    "    - Reads Task2 frames from frames_dir\n",
    "    - Builds a raw input video (input_video_path)\n",
    "    - Runs Faster R-CNN + DeepSORT on preprocessed frames\n",
    "    - Builds a tracked video (tracked_video_path)\n",
    "    - Saves MOT-style tracks to tracks_txt_path\n",
    "    - Returns: dict[frame_idx] -> person_count (from detector boxes)\n",
    "    \"\"\"\n",
    "    # Load detector + tracker\n",
    "    model, device = load_frcnn_detector(device)\n",
    "    tracker = init_deepsort_task2()\n",
    "\n",
    "    image_paths = sorted(frames_dir.glob(\"*.jpg\"))\n",
    "    if not image_paths:\n",
    "        raise FileNotFoundError(f\"No .jpg files found in {frames_dir}\")\n",
    "\n",
    "    # Read first frame to get size\n",
    "    first_frame = cv2.imread(str(image_paths[0]))\n",
    "    if first_frame is None:\n",
    "        raise RuntimeError(f\"Could not read first frame: {image_paths[0]}\")\n",
    "\n",
    "    height, width = first_frame.shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n",
    "    # Video writers\n",
    "    input_writer = cv2.VideoWriter(str(input_video_path), fourcc, fps, (width, height))\n",
    "    tracked_writer = cv2.VideoWriter(str(tracked_video_path), fourcc, fps, (width, height))\n",
    "\n",
    "    # Outputs\n",
    "    track_lines = []      # for MOT-style txt\n",
    "    frame_counts = {}     # frame_idx -> person_count\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_path in image_paths:\n",
    "            frame_idx += 1\n",
    "\n",
    "            frame_bgr = cv2.imread(str(img_path))\n",
    "            if frame_bgr is None:\n",
    "                print(f\"WARNING: could not read {img_path}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            original_bgr = frame_bgr.copy()\n",
    "\n",
    "            # Preprocess for detector\n",
    "            frame_bgr = preprocess_frame(frame_bgr)\n",
    "\n",
    "            # Write original raw frame to input video\n",
    "            input_writer.write(original_bgr)\n",
    "\n",
    "            # Prepare image for detector (RGB) using preprocessed frame\n",
    "            rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "            pil_img = Image.fromarray(rgb)\n",
    "            tensor = F.to_tensor(pil_img).to(device)\n",
    "\n",
    "            outputs = model([tensor])[0]\n",
    "            boxes = outputs[\"boxes\"].cpu()\n",
    "            labels = outputs[\"labels\"].cpu()\n",
    "            scores = outputs[\"scores\"].cpu()\n",
    "\n",
    "            detections = []\n",
    "            person_count = 0\n",
    "\n",
    "            # Build detections for DeepSort\n",
    "            for box, label, score in zip(boxes, labels, scores):\n",
    "                if label.item() != 1:  # COCO: 1 = person\n",
    "                    continue\n",
    "                if score.item() < score_thresh:\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = box.tolist()\n",
    "\n",
    "                # Clamp to frame\n",
    "                x1 = max(0.0, min(x1, width - 1.0))\n",
    "                x2 = max(0.0, min(x2, width - 1.0))\n",
    "                y1 = max(0.0, min(y1, height - 1.0))\n",
    "                y2 = max(0.0, min(y2, height - 1.0))\n",
    "\n",
    "                if x2 <= x1 or y2 <= y1:\n",
    "                    continue\n",
    "\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "\n",
    "                detections.append(([x1, y1, w, h], float(score.item()), \"person\"))\n",
    "                person_count += 1\n",
    "\n",
    "            # Update tracker\n",
    "            tracks = tracker.update_tracks(detections, frame=frame_bgr)\n",
    "\n",
    "            # Draw tracks and build MOT lines\n",
    "            for trk in tracks:\n",
    "                if not trk.is_confirmed() or trk.time_since_update > 0:\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = map(int, trk.to_ltrb())\n",
    "\n",
    "                # Clamp\n",
    "                x1 = max(0, min(x1, width - 1))\n",
    "                x2 = max(0, min(x2, width - 1))\n",
    "                y1 = max(0, min(y1, height - 1))\n",
    "                y2 = max(0, min(y2, height - 1))\n",
    "\n",
    "                bb_left = x1\n",
    "                bb_top = y1\n",
    "                bb_width = max(0, x2 - x1)\n",
    "                bb_height = max(0, y2 - y1)\n",
    "                track_id = trk.track_id\n",
    "\n",
    "                # Draw rectangle + ID\n",
    "                cv2.rectangle(\n",
    "                    frame_bgr,\n",
    "                    (bb_left, bb_top),\n",
    "                    (bb_left + bb_width, bb_top + bb_height),\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                )\n",
    "                cv2.putText(\n",
    "                    frame_bgr,\n",
    "                    f\"ID {track_id}\",\n",
    "                    (bb_left, max(0, bb_top - 5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 0),\n",
    "                    1,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "\n",
    "                # MOT-style line: <frame>, <id>, <bb_left>, <bb_top>, <bb_width>, <bb_height>\n",
    "                track_lines.append(\n",
    "                    f\"{frame_idx}, {track_id}, {bb_left}, {bb_top}, {bb_width}, {bb_height}\\n\"\n",
    "                )\n",
    "\n",
    "            # Write tracked frame (preprocessed + annotations)\n",
    "            tracked_writer.write(frame_bgr)\n",
    "\n",
    "            # Save count for this frame (detector-based, not unique IDs)\n",
    "            frame_counts[frame_idx] = person_count\n",
    "\n",
    "            print(\n",
    "                f\"Frame {frame_idx:4d}: {person_count:2d} people,\"\n",
    "                f\" {len(detections)} detections, {len(tracks)} tracks\"\n",
    "            )\n",
    "\n",
    "    # Release videos\n",
    "    input_writer.release()\n",
    "    tracked_writer.release()\n",
    "\n",
    "    # Write tracks txt\n",
    "    tracks_txt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with tracks_txt_path.open(\"w\") as f:\n",
    "        f.writelines(track_lines)\n",
    "\n",
    "    print(f\"\\nSaved input video to   {input_video_path}\")\n",
    "    print(f\"Saved tracked video to {tracked_video_path}\")\n",
    "    print(f\"Saved tracks to        {tracks_txt_path}\")\n",
    "\n",
    "    return frame_counts\n",
    "\n",
    "\n",
    "# ---- Run Task2 processing and get per-frame counts ----\n",
    "task2_frame_counts = process_task2_frames(\n",
    "    frames_dir=TASK2_IMAGES_DIR,\n",
    "    input_video_path=TASK2_INPUT_VIDEO,\n",
    "    tracked_video_path=TASK2_OUTPUT_VIDEO,\n",
    "    tracks_txt_path=TASK2_TRACKS_TXT,\n",
    "    fps=FPS_TASK2,\n",
    "    device=DEVICE_T2,\n",
    "    score_thresh=SCORE_THRESH_T2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ede7cc",
   "metadata": {},
   "source": [
    "### 4.2 Save frame counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70812d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved counts to task2_count.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4.2 Save Task2 frame counts to CSV for Kaggle\n",
    "#     Format:\n",
    "#       Number,Count\n",
    "#       1,12\n",
    "#       2,15\n",
    "#       ...\n",
    "# ============================================\n",
    "def save_counts_to_csv(frame_counts: dict, csv_path: Path):\n",
    "    \"\"\"\n",
    "    frame_counts: dict[frame_idx] -> count\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for frame_idx in sorted(frame_counts.keys()):\n",
    "        data.append({\"Number\": frame_idx, \"Count\": frame_counts[frame_idx]})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved counts to {csv_path}\")\n",
    "\n",
    "\n",
    "save_counts_to_csv(task2_frame_counts, TASK2_COUNTS_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a1ea0",
   "metadata": {},
   "source": [
    "### DEBUG: Run Sweep with Multiple Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9279da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep for conf\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Conf values to try\n",
    "# CONF_SWEEP = [0.80, 0.70, 0.60, 0.50, 0.40, 0.30, 0.25, 0.20, 0.15, 0.10]\n",
    "\n",
    "# sweep_results = []\n",
    "\n",
    "# for conf in CONF_SWEEP:\n",
    "#     YOLO_CONF = conf  # update global used inside run_tracking / track_on_image_sequence\n",
    "\n",
    "#     print(\"\\n\" + \"=\" * 50)\n",
    "#     print(f\"Running sweep with YOLO_CONF = {conf:.2f}\")\n",
    "#     print(\"=\" * 50)\n",
    "\n",
    "#     # ---- Task 1: tracking + MOTA ----\n",
    "#     # unique outputs per conf\n",
    "#     task1_video_out = Path(f\"task1_conf{int(conf*100):03d}.mp4\")\n",
    "#     task1_tracks_out = Path(f\"task1_tracks_conf{int(conf*100):03d}.txt\")\n",
    "\n",
    "#     # fresh tracker for each run\n",
    "#     yolo_model_t1 = init_yolo()\n",
    "#     deepsort_t1 = init_deepsort()\n",
    "\n",
    "#     run_tracking(\n",
    "#         TASK1_INPUT_VIDEO,\n",
    "#         task1_video_out,\n",
    "#         task1_tracks_out,\n",
    "#         yolo_model_t1,\n",
    "#         deepsort_t1,\n",
    "#         fps=FPS_TASK1,\n",
    "#         conf=YOLO_CONF\n",
    "#     )\n",
    "\n",
    "#     # compute MOTA for this conf\n",
    "#     gt_by_frame = load_gt(TASK1_GT_PATH)\n",
    "#     pred_by_frame = load_predictions(task1_tracks_out)\n",
    "\n",
    "#     mota, total_FP, total_FN, total_IDSW, total_GT = compute_mota(\n",
    "#         gt_by_frame, pred_by_frame, iou_threshold=0.5\n",
    "#     )\n",
    "\n",
    "#     print(f\"[Task1] conf={conf:.2f}  MOTA={mota:.4f}  FP={total_FP}  FN={total_FN}  IDSW={total_IDSW}\")\n",
    "\n",
    "#     # ---- Task 2: counts + CSV ----\n",
    "#     task2_video_out = Path(f\"task2_conf{int(conf*100):03d}.mp4\")\n",
    "#     task2_csv_out   = Path(f\"task2_count_conf{int(conf*100):03d}.csv\")\n",
    "\n",
    "#     yolo_model_t2 = init_yolo()\n",
    "#     deepsort_t2 = init_deepsort()\n",
    "\n",
    "#     task2_counts = track_on_image_sequence(\n",
    "#         TASK2_IMAGES_DIR,\n",
    "#         task2_video_out,\n",
    "#         yolo_model_t2,\n",
    "#         deepsort_t2,\n",
    "#         fps=FPS_TASK2,\n",
    "#         conf=YOLO_CONF\n",
    "#     )\n",
    "\n",
    "#     save_counts_to_csv(task2_counts, task2_csv_out)\n",
    "\n",
    "#     # store summary\n",
    "#     sweep_results.append({\n",
    "#         \"conf\": conf,\n",
    "#         \"MOTA\": mota,\n",
    "#         \"FP\": total_FP,\n",
    "#         \"FN\": total_FN,\n",
    "#         \"IDSW\": total_IDSW,\n",
    "#         \"GT\": total_GT,\n",
    "#         \"task1_video\": str(task1_video_out),\n",
    "#         \"task1_tracks\": str(task1_tracks_out),\n",
    "#         \"task2_csv\": str(task2_csv_out),\n",
    "#     })\n",
    "\n",
    "# print(\"\\n=== Sweep summary ===\")\n",
    "# for r in sweep_results:\n",
    "#     print(\n",
    "#         f\"conf={r['conf']:.2f}  MOTA={r['MOTA']:.4f}  \"\n",
    "#         f\"FP={r['FP']}  FN={r['FN']}  IDSW={r['IDSW']}  \"\n",
    "#         f\"CSV={r['task2_csv']}\"\n",
    "#     )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
